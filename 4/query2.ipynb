{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIhzyo2wiKRg"
      },
      "source": [
        "# **Exercise 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMb-7FAdiEw-",
        "outputId": "e21bad43-0044-4f1c-f3d2-5f2502047614"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22119/22119 [01:51<00:00, 197.58it/s]\n",
            "100%|██████████| 4066/4066 [00:19<00:00, 210.76it/s]\n",
            "100%|██████████| 4321/4321 [00:23<00:00, 185.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 1000\n",
            "Development set size: 200\n",
            "Test set size: 200\n",
            "Average sentence length:  21.79\n",
            "NUmber of words:  492\n",
            "Vocabulary size:  6430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import spacy\n",
        "import requests\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, precision_recall_curve, auc, precision_recall_fscore_support\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout, LSTM, Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "# Load the spaCy model with pre-trained word embeddings\n",
        "word_embeddings = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def download_and_read_data(file_url, size):\n",
        "    response = requests.get(file_url)\n",
        "    lines = response.text.splitlines()\n",
        "    sentences = []\n",
        "    current_sentence = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.startswith('#') or line == '':\n",
        "            if current_sentence:\n",
        "                sentences.append(current_sentence)\n",
        "                current_sentence = []\n",
        "                if(len(sentences) == size):\n",
        "                    break\n",
        "        else:\n",
        "            parts = line.split('\\t')\n",
        "            if len(parts) > 3:\n",
        "                current_sentence.append((parts[1], parts[3]))  # (word, pos_tag)\n",
        "    return sentences if not current_sentence else sentences + [current_sentence]\n",
        "\n",
        "# URLs\n",
        "train_url = f\"https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/master/en_ewt-ud-train.conllu\"\n",
        "dev_url = f\"https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/master/en_ewt-ud-dev.conllu\"\n",
        "test_url = f\"https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/master/en_ewt-ud-test.conllu\"\n",
        "\n",
        "# Read and preprocess data\n",
        "subset_size = 1000\n",
        "train_data = download_and_read_data(train_url, subset_size)\n",
        "dev_data = download_and_read_data(dev_url, int(subset_size/5))\n",
        "test_data = download_and_read_data(test_url, int(subset_size/5))\n",
        "\n",
        "# Extract words and POS tags\n",
        "def extract_features(sentence, i):\n",
        "    word = sentence[i][0]\n",
        "    pos = sentence[i][1]\n",
        "\n",
        "    # # Features: the current word and its two neighbors\n",
        "    # features = [\n",
        "    #     word,\n",
        "    #     sentence[i - 1][0] if i > 0 else '*PAD*',\n",
        "    #     sentence[i + 1][0] if i < len(sentence) - 1 else '*PAD*',\n",
        "    # ]\n",
        "    # return features, pos\n",
        "    return [word], pos\n",
        "\n",
        "# Create training, development, and test datasets\n",
        "def create_dataset(data):\n",
        "    X, y = [], []\n",
        "    for sentence in data:\n",
        "        X_sentence = []\n",
        "        y_sentence = []\n",
        "        for i in range(len(sentence)):\n",
        "            features, pos = extract_features(sentence, i)\n",
        "            #X_sentence.append(features)\n",
        "            X.append(features)\n",
        "            y.append(pos)\n",
        "        #X.append(X_sentence)\n",
        "        #y.append(y_sentence)\n",
        "    return X, y\n",
        "\n",
        "\n",
        "X_train, y_train = create_dataset(train_data)\n",
        "X_dev, y_dev = create_dataset(dev_data)\n",
        "X_test, y_test = create_dataset(test_data)\n",
        "\n",
        "\n",
        "X_train_embed = []\n",
        "X_dev_embed = []\n",
        "X_test_embed = []\n",
        "\n",
        "# Convert words to spaCy word vectors\n",
        "for dataset, X_embed in zip([X_train, X_dev, X_test], [X_train_embed, X_dev_embed, X_test_embed]):\n",
        "    for sentence in tqdm.tqdm(range(len(dataset))):\n",
        "        word_vectors = [word_embeddings(word).vector for word in dataset[sentence]]\n",
        "        X_embed.append(np.array(word_vectors))\n",
        "\n",
        "\n",
        "# Encode POS tags\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "y_train_encoded = label_encoder.transform(y_train)\n",
        "y_dev_encoded = label_encoder.transform(y_dev)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "\n",
        "# Convert tags to one-hot encoding\n",
        "y_train_onehot = to_categorical(y_train_encoded, num_classes=num_classes)\n",
        "y_dev_onehot = to_categorical(y_dev_encoded, num_classes=num_classes)\n",
        "y_test_onehot = to_categorical(y_test_encoded, num_classes=num_classes)\n",
        "\n",
        "# constants\n",
        "embedding_dim = word_embeddings('test').vector.shape[0]\n",
        "\n",
        "\n",
        "# statistics\n",
        "print(\"Training set size:\", len(train_data))\n",
        "print(\"Development set size:\", len(dev_data))\n",
        "print(\"Test set size:\", len(test_data))\n",
        "lengths = [len(i) for i in train_data] + [len(i) for i in dev_data] + [len(i) for i in test_data]\n",
        "print(\"Average sentence length: \", sum(lengths)/len(lengths))\n",
        "words_set = set()\n",
        "for sentences in zip([train_data, dev_data, test_data]):\n",
        "    for sent in sentences:\n",
        "        for w in sent:\n",
        "            words_set.add(w[0])\n",
        "print(\"NUmber of words: \", len(words_set))\n",
        "print(\"Vocabulary size: \", len(word_embeddings.vocab))\n",
        "\n",
        "del word_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ7RN2dyic2J"
      },
      "source": [
        "# **Find best hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RG09s2kijVN",
        "outputId": "7609c41f-8cbc-441a-def2-95351cf9cd62"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dev accuracy for params:  (128, 0.2, 0.0001, 50, 3)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128/128 [==============================] - 1s 5ms/step - loss: 0.2786 - accuracy: 0.9097\n",
            "Dev accuracy for params:  (128, 0.2, 0.0001, 50, 4)\n",
            "128/128 [==============================] - 1s 6ms/step - loss: 0.2803 - accuracy: 0.9088\n",
            "Dev accuracy for params:  (128, 0.2, 0.0001, 50, 5)\n",
            "128/128 [==============================] - 1s 6ms/step - loss: 0.2842 - accuracy: 0.9080\n",
            "Dev accuracy for params:  (128, 0.2, 0.001, 50, 3)\n",
            "128/128 [==============================] - 1s 5ms/step - loss: 0.4135 - accuracy: 0.9016\n",
            "Dev accuracy for params:  (128, 0.2, 0.001, 50, 4)\n",
            "128/128 [==============================] - 1s 6ms/step - loss: 0.4151 - accuracy: 0.8918\n",
            "Dev accuracy for params:  (128, 0.2, 0.001, 50, 5)\n",
            "128/128 [==============================] - 1s 7ms/step - loss: 0.3879 - accuracy: 0.9006\n",
            "Dev accuracy for params:  (128, 0.2, 0.01, 50, 3)\n",
            "128/128 [==============================] - 1s 5ms/step - loss: 0.3176 - accuracy: 0.9004\n",
            "Dev accuracy for params:  (128, 0.2, 0.01, 50, 4)\n",
            "128/128 [==============================] - 1s 6ms/step - loss: 0.3358 - accuracy: 0.9004\n",
            "Dev accuracy for params:  (128, 0.2, 0.01, 50, 5)\n",
            "128/128 [==============================] - 1s 6ms/step - loss: 0.3661 - accuracy: 0.8979\n",
            "Dev accuracy for params:  (128, 0.4, 0.0001, 50, 3)\n",
            "128/128 [==============================] - 1s 5ms/step - loss: 0.2766 - accuracy: 0.9090\n",
            "Dev accuracy for params:  (128, 0.4, 0.0001, 50, 4)\n",
            "128/128 [==============================] - 1s 6ms/step - loss: 0.2750 - accuracy: 0.9092\n",
            "Dev accuracy for params:  (128, 0.4, 0.0001, 50, 5)\n",
            "128/128 [==============================] - 1s 6ms/step - loss: 0.2872 - accuracy: 0.9080\n",
            "Dev accuracy for params:  (128, 0.4, 0.001, 50, 3)\n",
            "128/128 [==============================] - 1s 5ms/step - loss: 0.3628 - accuracy: 0.9033\n",
            "Dev accuracy for params:  (128, 0.4, 0.001, 50, 4)\n",
            "128/128 [==============================] - 1s 6ms/step - loss: 0.3486 - accuracy: 0.9036\n",
            "Dev accuracy for params:  (128, 0.4, 0.001, 50, 5)\n",
            "128/128 [==============================] - 1s 6ms/step - loss: 0.3567 - accuracy: 0.9021\n",
            "Dev accuracy for params:  (128, 0.4, 0.01, 50, 3)\n",
            "128/128 [==============================] - 1s 5ms/step - loss: 0.3120 - accuracy: 0.9068\n",
            "Dev accuracy for params:  (128, 0.4, 0.01, 50, 4)\n",
            "128/128 [==============================] - 1s 6ms/step - loss: 0.3587 - accuracy: 0.8910\n",
            "Dev accuracy for params:  (128, 0.4, 0.01, 50, 5)\n",
            "128/128 [==============================] - 1s 6ms/step - loss: 0.4138 - accuracy: 0.8871\n",
            "Dev accuracy for params:  (128, 0.6, 0.0001, 50, 3)\n",
            "128/128 [==============================] - 1s 5ms/step - loss: 0.2776 - accuracy: 0.9107\n",
            "Dev accuracy for params:  (128, 0.6, 0.0001, 50, 4)\n",
            "128/128 [==============================] - 1s 6ms/step - loss: 0.2892 - accuracy: 0.9092\n",
            "Dev accuracy for params:  (128, 0.6, 0.0001, 50, 5)\n",
            "128/128 [==============================] - 1s 6ms/step - loss: 0.2970 - accuracy: 0.9092\n",
            "Dev accuracy for params:  (128, 0.6, 0.001, 50, 3)\n",
            "128/128 [==============================] - 1s 5ms/step - loss: 0.3295 - accuracy: 0.9105\n",
            "Dev accuracy for params:  (128, 0.6, 0.001, 50, 4)\n",
            "128/128 [==============================] - 1s 7ms/step - loss: 0.3219 - accuracy: 0.9085\n",
            "Dev accuracy for params:  (128, 0.6, 0.001, 50, 5)\n",
            "128/128 [==============================] - 1s 7ms/step - loss: 0.3179 - accuracy: 0.9056\n",
            "Dev accuracy for params:  (128, 0.6, 0.01, 50, 3)\n",
            "128/128 [==============================] - 1s 6ms/step - loss: 0.3718 - accuracy: 0.9019\n",
            "Dev accuracy for params:  (128, 0.6, 0.01, 50, 4)\n",
            "128/128 [==============================] - 1s 8ms/step - loss: 0.4888 - accuracy: 0.8810\n",
            "Dev accuracy for params:  (128, 0.6, 0.01, 50, 5)\n",
            "128/128 [==============================] - 1s 7ms/step - loss: 0.7035 - accuracy: 0.7959\n",
            "(0.9092473983764648, 0.2750409245491028, (128, 0.4, 0.0001, 50, 4))\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model(hidden_units, dropout_rate, lr, epochs, stacked_l):\n",
        "  model = Sequential()\n",
        "  for _ in range(stacked_l-1):\n",
        "      model.add(Bidirectional(LSTM(units=hidden_units, return_sequences=True)))\n",
        "      model.add(Dropout(dropout_rate))\n",
        "\n",
        "  model.add(Bidirectional(LSTM(units=hidden_units, return_sequences=False)))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  filepath = 'temp_best_model.hdf5'\n",
        "  checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss',\n",
        "                              verbose=0, save_best_only=True, mode='min')\n",
        "  callbacks = [checkpoint]\n",
        "\n",
        "\n",
        "  history = model.fit(np.array(X_train_embed, dtype='float32'), y_train_onehot, epochs=epochs,\n",
        "                      validation_data=(np.array(X_dev_embed, dtype='float32'), y_dev_onehot),\n",
        "                      callbacks=callbacks, batch_size=32, verbose = 0)\n",
        "\n",
        "\n",
        "  loss, accuracy = model.evaluate(np.array(X_dev_embed), y_dev_onehot)\n",
        "  del model\n",
        "  del history\n",
        "  return accuracy, loss\n",
        "\n",
        "def tune_hyperparam(params):\n",
        "  best_acc = 0\n",
        "  best_loss = 100\n",
        "  best_params = ()\n",
        "  for hdu in params[\"hidden_units\"]:\n",
        "    for dro in params[\"dropout_rate\"]:\n",
        "      for lr in params[\"learning_rate\"]:\n",
        "        for ep in params[\"epochs\"]:\n",
        "          for sl in params[\"stacked_layers\"]:\n",
        "            print(\"Dev accuracy for params: \", (hdu, dro, lr, ep, sl))\n",
        "            acc, loss = evaluate_model(hdu, dro, lr, ep, sl)\n",
        "            if loss < best_loss or (loss == best_loss and acc > best_acc):\n",
        "              best_acc = acc\n",
        "              best_loss = loss\n",
        "              best_params = (hdu, dro, lr, ep, sl)\n",
        "\n",
        "  return best_acc, best_loss, best_params\n",
        "\n",
        "hyper_parameters = {\n",
        "    \"hidden_units\": [64, 128, 256],\n",
        "    \"dropout_rate\": [0.2, 0.4, 0.6],\n",
        "    \"learning_rate\": [0.0001, 0.001, 0.01],\n",
        "    \"epochs\": [50],\n",
        "    \"stacked_layers\": [3, 4, 5]\n",
        "}\n",
        "\n",
        "print(tune_hyperparam(hyper_parameters))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3q3dfMyinbv"
      },
      "source": [
        "# **Build model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Womt6NEPipEZ",
        "outputId": "db8cde94-1efa-4f9c-cddb-adde407f8585"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "688/692 [============================>.] - ETA: 0s - loss: 1.6671 - accuracy: 0.6093\n",
            "Epoch 1: val_loss improved from inf to 0.63320, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 27s 14ms/step - loss: 1.6617 - accuracy: 0.6104 - val_loss: 0.6332 - val_accuracy: 0.8325\n",
            "Epoch 2/100\n",
            " 12/692 [..............................] - ETA: 6s - loss: 0.6501 - accuracy: 0.8333"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "690/692 [============================>.] - ETA: 0s - loss: 0.5131 - accuracy: 0.8587\n",
            "Epoch 2: val_loss improved from 0.63320 to 0.40134, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 9s 13ms/step - loss: 0.5134 - accuracy: 0.8585 - val_loss: 0.4013 - val_accuracy: 0.8743\n",
            "Epoch 3/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.3931 - accuracy: 0.8836\n",
            "Epoch 3: val_loss improved from 0.40134 to 0.35022, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 7s 10ms/step - loss: 0.3930 - accuracy: 0.8837 - val_loss: 0.3502 - val_accuracy: 0.8864\n",
            "Epoch 4/100\n",
            "687/692 [============================>.] - ETA: 0s - loss: 0.3533 - accuracy: 0.8917\n",
            "Epoch 4: val_loss improved from 0.35022 to 0.32562, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.3538 - accuracy: 0.8917 - val_loss: 0.3256 - val_accuracy: 0.8992\n",
            "Epoch 5/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.3286 - accuracy: 0.9009\n",
            "Epoch 5: val_loss improved from 0.32562 to 0.30925, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 7s 10ms/step - loss: 0.3286 - accuracy: 0.9009 - val_loss: 0.3093 - val_accuracy: 0.9033\n",
            "Epoch 6/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.3195 - accuracy: 0.9012\n",
            "Epoch 6: val_loss improved from 0.30925 to 0.30252, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.3195 - accuracy: 0.9012 - val_loss: 0.3025 - val_accuracy: 0.9036\n",
            "Epoch 7/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.3108 - accuracy: 0.9016\n",
            "Epoch 7: val_loss improved from 0.30252 to 0.29591, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.3107 - accuracy: 0.9016 - val_loss: 0.2959 - val_accuracy: 0.9065\n",
            "Epoch 8/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.3036 - accuracy: 0.9024\n",
            "Epoch 8: val_loss improved from 0.29591 to 0.29119, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 7s 11ms/step - loss: 0.3036 - accuracy: 0.9024 - val_loss: 0.2912 - val_accuracy: 0.9048\n",
            "Epoch 9/100\n",
            "687/692 [============================>.] - ETA: 0s - loss: 0.2975 - accuracy: 0.9045\n",
            "Epoch 9: val_loss improved from 0.29119 to 0.29008, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2973 - accuracy: 0.9046 - val_loss: 0.2901 - val_accuracy: 0.9063\n",
            "Epoch 10/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.2922 - accuracy: 0.9050\n",
            "Epoch 10: val_loss improved from 0.29008 to 0.28580, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 7s 10ms/step - loss: 0.2923 - accuracy: 0.9050 - val_loss: 0.2858 - val_accuracy: 0.9065\n",
            "Epoch 11/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.2892 - accuracy: 0.9038\n",
            "Epoch 11: val_loss improved from 0.28580 to 0.28302, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2893 - accuracy: 0.9037 - val_loss: 0.2830 - val_accuracy: 0.9083\n",
            "Epoch 12/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.2833 - accuracy: 0.9069\n",
            "Epoch 12: val_loss improved from 0.28302 to 0.28063, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 8s 11ms/step - loss: 0.2830 - accuracy: 0.9070 - val_loss: 0.2806 - val_accuracy: 0.9065\n",
            "Epoch 13/100\n",
            "687/692 [============================>.] - ETA: 0s - loss: 0.2800 - accuracy: 0.9084\n",
            "Epoch 13: val_loss improved from 0.28063 to 0.28016, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 8s 11ms/step - loss: 0.2793 - accuracy: 0.9086 - val_loss: 0.2802 - val_accuracy: 0.9080\n",
            "Epoch 14/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.2770 - accuracy: 0.9084\n",
            "Epoch 14: val_loss improved from 0.28016 to 0.27937, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 9s 12ms/step - loss: 0.2770 - accuracy: 0.9084 - val_loss: 0.2794 - val_accuracy: 0.9051\n",
            "Epoch 15/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.2766 - accuracy: 0.9075\n",
            "Epoch 15: val_loss improved from 0.27937 to 0.27742, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 7s 10ms/step - loss: 0.2766 - accuracy: 0.9075 - val_loss: 0.2774 - val_accuracy: 0.9051\n",
            "Epoch 16/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.2720 - accuracy: 0.9056\n",
            "Epoch 16: val_loss improved from 0.27742 to 0.27576, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2720 - accuracy: 0.9056 - val_loss: 0.2758 - val_accuracy: 0.9048\n",
            "Epoch 17/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.2686 - accuracy: 0.9067\n",
            "Epoch 17: val_loss did not improve from 0.27576\n",
            "692/692 [==============================] - 7s 11ms/step - loss: 0.2687 - accuracy: 0.9067 - val_loss: 0.2758 - val_accuracy: 0.9078\n",
            "Epoch 18/100\n",
            "687/692 [============================>.] - ETA: 0s - loss: 0.2684 - accuracy: 0.9083\n",
            "Epoch 18: val_loss improved from 0.27576 to 0.27449, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2684 - accuracy: 0.9084 - val_loss: 0.2745 - val_accuracy: 0.9061\n",
            "Epoch 19/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.2643 - accuracy: 0.9089\n",
            "Epoch 19: val_loss did not improve from 0.27449\n",
            "692/692 [==============================] - 9s 13ms/step - loss: 0.2642 - accuracy: 0.9089 - val_loss: 0.2767 - val_accuracy: 0.9107\n",
            "Epoch 20/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.2612 - accuracy: 0.9108\n",
            "Epoch 20: val_loss improved from 0.27449 to 0.27258, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 7s 10ms/step - loss: 0.2612 - accuracy: 0.9108 - val_loss: 0.2726 - val_accuracy: 0.9063\n",
            "Epoch 21/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.2575 - accuracy: 0.9122\n",
            "Epoch 21: val_loss improved from 0.27258 to 0.27102, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 9s 12ms/step - loss: 0.2575 - accuracy: 0.9122 - val_loss: 0.2710 - val_accuracy: 0.9063\n",
            "Epoch 22/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.2573 - accuracy: 0.9089\n",
            "Epoch 22: val_loss improved from 0.27102 to 0.27026, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 7s 10ms/step - loss: 0.2573 - accuracy: 0.9089 - val_loss: 0.2703 - val_accuracy: 0.9070\n",
            "Epoch 23/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.2555 - accuracy: 0.9111\n",
            "Epoch 23: val_loss improved from 0.27026 to 0.26991, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2555 - accuracy: 0.9111 - val_loss: 0.2699 - val_accuracy: 0.9092\n",
            "Epoch 24/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.2562 - accuracy: 0.9103\n",
            "Epoch 24: val_loss improved from 0.26991 to 0.26971, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2562 - accuracy: 0.9103 - val_loss: 0.2697 - val_accuracy: 0.9075\n",
            "Epoch 25/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.2518 - accuracy: 0.9131\n",
            "Epoch 25: val_loss improved from 0.26971 to 0.26963, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 8s 11ms/step - loss: 0.2518 - accuracy: 0.9131 - val_loss: 0.2696 - val_accuracy: 0.9088\n",
            "Epoch 26/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.2511 - accuracy: 0.9124\n",
            "Epoch 26: val_loss improved from 0.26963 to 0.26900, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2511 - accuracy: 0.9124 - val_loss: 0.2690 - val_accuracy: 0.9080\n",
            "Epoch 27/100\n",
            "688/692 [============================>.] - ETA: 0s - loss: 0.2502 - accuracy: 0.9120\n",
            "Epoch 27: val_loss did not improve from 0.26900\n",
            "692/692 [==============================] - 7s 11ms/step - loss: 0.2499 - accuracy: 0.9122 - val_loss: 0.2710 - val_accuracy: 0.9070\n",
            "Epoch 28/100\n",
            "689/692 [============================>.] - ETA: 0s - loss: 0.2456 - accuracy: 0.9128\n",
            "Epoch 28: val_loss did not improve from 0.26900\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2458 - accuracy: 0.9128 - val_loss: 0.2718 - val_accuracy: 0.9085\n",
            "Epoch 29/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.2457 - accuracy: 0.9129\n",
            "Epoch 29: val_loss did not improve from 0.26900\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2457 - accuracy: 0.9129 - val_loss: 0.2714 - val_accuracy: 0.9085\n",
            "Epoch 30/100\n",
            "687/692 [============================>.] - ETA: 0s - loss: 0.2436 - accuracy: 0.9130\n",
            "Epoch 30: val_loss did not improve from 0.26900\n",
            "692/692 [==============================] - 8s 11ms/step - loss: 0.2433 - accuracy: 0.9131 - val_loss: 0.2706 - val_accuracy: 0.9090\n",
            "Epoch 31/100\n",
            "688/692 [============================>.] - ETA: 0s - loss: 0.2423 - accuracy: 0.9137\n",
            "Epoch 31: val_loss improved from 0.26900 to 0.26866, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2419 - accuracy: 0.9138 - val_loss: 0.2687 - val_accuracy: 0.9122\n",
            "Epoch 32/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.2401 - accuracy: 0.9156\n",
            "Epoch 32: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 7s 11ms/step - loss: 0.2401 - accuracy: 0.9156 - val_loss: 0.2712 - val_accuracy: 0.9117\n",
            "Epoch 33/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.2403 - accuracy: 0.9129\n",
            "Epoch 33: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2403 - accuracy: 0.9129 - val_loss: 0.2692 - val_accuracy: 0.9088\n",
            "Epoch 34/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.2398 - accuracy: 0.9147\n",
            "Epoch 34: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 7s 10ms/step - loss: 0.2398 - accuracy: 0.9147 - val_loss: 0.2702 - val_accuracy: 0.9110\n",
            "Epoch 35/100\n",
            "687/692 [============================>.] - ETA: 0s - loss: 0.2376 - accuracy: 0.9153\n",
            "Epoch 35: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2370 - accuracy: 0.9155 - val_loss: 0.2691 - val_accuracy: 0.9115\n",
            "Epoch 36/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.2368 - accuracy: 0.9156\n",
            "Epoch 36: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2368 - accuracy: 0.9156 - val_loss: 0.2704 - val_accuracy: 0.9112\n",
            "Epoch 37/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.2350 - accuracy: 0.9155\n",
            "Epoch 37: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 7s 11ms/step - loss: 0.2350 - accuracy: 0.9155 - val_loss: 0.2707 - val_accuracy: 0.9129\n",
            "Epoch 38/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.2353 - accuracy: 0.9169\n",
            "Epoch 38: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2353 - accuracy: 0.9169 - val_loss: 0.2713 - val_accuracy: 0.9112\n",
            "Epoch 39/100\n",
            "689/692 [============================>.] - ETA: 0s - loss: 0.2327 - accuracy: 0.9159\n",
            "Epoch 39: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2324 - accuracy: 0.9159 - val_loss: 0.2693 - val_accuracy: 0.9107\n",
            "Epoch 40/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.2313 - accuracy: 0.9162\n",
            "Epoch 40: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 9s 12ms/step - loss: 0.2313 - accuracy: 0.9162 - val_loss: 0.2731 - val_accuracy: 0.9092\n",
            "Epoch 41/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.2305 - accuracy: 0.9162\n",
            "Epoch 41: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2305 - accuracy: 0.9162 - val_loss: 0.2711 - val_accuracy: 0.9115\n",
            "Epoch 42/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.2296 - accuracy: 0.9176\n",
            "Epoch 42: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 7s 11ms/step - loss: 0.2295 - accuracy: 0.9176 - val_loss: 0.2710 - val_accuracy: 0.9105\n",
            "Epoch 43/100\n",
            "689/692 [============================>.] - ETA: 0s - loss: 0.2290 - accuracy: 0.9172\n",
            "Epoch 43: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2288 - accuracy: 0.9173 - val_loss: 0.2708 - val_accuracy: 0.9097\n",
            "Epoch 44/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.2277 - accuracy: 0.9174\n",
            "Epoch 44: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 7s 10ms/step - loss: 0.2276 - accuracy: 0.9174 - val_loss: 0.2741 - val_accuracy: 0.9129\n",
            "Epoch 45/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.2260 - accuracy: 0.9175\n",
            "Epoch 45: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2259 - accuracy: 0.9175 - val_loss: 0.2691 - val_accuracy: 0.9095\n",
            "Epoch 46/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.2263 - accuracy: 0.9182\n",
            "Epoch 46: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2266 - accuracy: 0.9181 - val_loss: 0.2707 - val_accuracy: 0.9105\n",
            "Epoch 47/100\n",
            "688/692 [============================>.] - ETA: 0s - loss: 0.2237 - accuracy: 0.9205\n",
            "Epoch 47: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 11ms/step - loss: 0.2235 - accuracy: 0.9206 - val_loss: 0.2765 - val_accuracy: 0.9112\n",
            "Epoch 48/100\n",
            "687/692 [============================>.] - ETA: 0s - loss: 0.2228 - accuracy: 0.9200\n",
            "Epoch 48: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 9s 12ms/step - loss: 0.2227 - accuracy: 0.9198 - val_loss: 0.2726 - val_accuracy: 0.9110\n",
            "Epoch 49/100\n",
            "688/692 [============================>.] - ETA: 0s - loss: 0.2228 - accuracy: 0.9187\n",
            "Epoch 49: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 7s 10ms/step - loss: 0.2222 - accuracy: 0.9188 - val_loss: 0.2700 - val_accuracy: 0.9120\n",
            "Epoch 50/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.2190 - accuracy: 0.9189\n",
            "Epoch 50: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2188 - accuracy: 0.9190 - val_loss: 0.2719 - val_accuracy: 0.9105\n",
            "Epoch 51/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.2206 - accuracy: 0.9176\n",
            "Epoch 51: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2206 - accuracy: 0.9176 - val_loss: 0.2709 - val_accuracy: 0.9127\n",
            "Epoch 52/100\n",
            "689/692 [============================>.] - ETA: 0s - loss: 0.2215 - accuracy: 0.9197\n",
            "Epoch 52: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 11ms/step - loss: 0.2221 - accuracy: 0.9195 - val_loss: 0.2730 - val_accuracy: 0.9144\n",
            "Epoch 53/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.2212 - accuracy: 0.9195\n",
            "Epoch 53: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2209 - accuracy: 0.9196 - val_loss: 0.2734 - val_accuracy: 0.9117\n",
            "Epoch 54/100\n",
            "689/692 [============================>.] - ETA: 0s - loss: 0.2181 - accuracy: 0.9199\n",
            "Epoch 54: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 7s 10ms/step - loss: 0.2178 - accuracy: 0.9200 - val_loss: 0.2726 - val_accuracy: 0.9105\n",
            "Epoch 55/100\n",
            "687/692 [============================>.] - ETA: 0s - loss: 0.2172 - accuracy: 0.9204\n",
            "Epoch 55: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2168 - accuracy: 0.9205 - val_loss: 0.2741 - val_accuracy: 0.9102\n",
            "Epoch 56/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.2195 - accuracy: 0.9196\n",
            "Epoch 56: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 7s 10ms/step - loss: 0.2195 - accuracy: 0.9196 - val_loss: 0.2749 - val_accuracy: 0.9110\n",
            "Epoch 57/100\n",
            "689/692 [============================>.] - ETA: 0s - loss: 0.2155 - accuracy: 0.9209\n",
            "Epoch 57: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2155 - accuracy: 0.9209 - val_loss: 0.2747 - val_accuracy: 0.9088\n",
            "Epoch 58/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.2135 - accuracy: 0.9209\n",
            "Epoch 58: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2135 - accuracy: 0.9208 - val_loss: 0.2749 - val_accuracy: 0.9110\n",
            "Epoch 59/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.2165 - accuracy: 0.9202\n",
            "Epoch 59: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 11ms/step - loss: 0.2166 - accuracy: 0.9202 - val_loss: 0.2755 - val_accuracy: 0.9124\n",
            "Epoch 60/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.2145 - accuracy: 0.9229\n",
            "Epoch 60: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 9s 12ms/step - loss: 0.2145 - accuracy: 0.9229 - val_loss: 0.2765 - val_accuracy: 0.9090\n",
            "Epoch 61/100\n",
            "687/692 [============================>.] - ETA: 0s - loss: 0.2144 - accuracy: 0.9214\n",
            "Epoch 61: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 7s 10ms/step - loss: 0.2148 - accuracy: 0.9211 - val_loss: 0.2755 - val_accuracy: 0.9095\n",
            "Epoch 62/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.2121 - accuracy: 0.9228\n",
            "Epoch 62: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2121 - accuracy: 0.9228 - val_loss: 0.2778 - val_accuracy: 0.9061\n",
            "Epoch 63/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.2107 - accuracy: 0.9222\n",
            "Epoch 63: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2107 - accuracy: 0.9221 - val_loss: 0.2782 - val_accuracy: 0.9083\n",
            "Epoch 64/100\n",
            "689/692 [============================>.] - ETA: 0s - loss: 0.2101 - accuracy: 0.9223\n",
            "Epoch 64: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 11ms/step - loss: 0.2103 - accuracy: 0.9222 - val_loss: 0.2785 - val_accuracy: 0.9100\n",
            "Epoch 65/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.2107 - accuracy: 0.9224\n",
            "Epoch 65: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2108 - accuracy: 0.9223 - val_loss: 0.2769 - val_accuracy: 0.9088\n",
            "Epoch 66/100\n",
            "689/692 [============================>.] - ETA: 0s - loss: 0.2119 - accuracy: 0.9220\n",
            "Epoch 66: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 7s 11ms/step - loss: 0.2119 - accuracy: 0.9220 - val_loss: 0.2766 - val_accuracy: 0.9127\n",
            "Epoch 67/100\n",
            "689/692 [============================>.] - ETA: 0s - loss: 0.2091 - accuracy: 0.9216\n",
            "Epoch 67: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2091 - accuracy: 0.9217 - val_loss: 0.2773 - val_accuracy: 0.9088\n",
            "Epoch 68/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.2073 - accuracy: 0.9236\n",
            "Epoch 68: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2072 - accuracy: 0.9237 - val_loss: 0.2767 - val_accuracy: 0.9070\n",
            "Epoch 69/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.2095 - accuracy: 0.9222\n",
            "Epoch 69: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 11ms/step - loss: 0.2093 - accuracy: 0.9223 - val_loss: 0.2784 - val_accuracy: 0.9110\n",
            "Epoch 70/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.2062 - accuracy: 0.9227\n",
            "Epoch 70: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2063 - accuracy: 0.9227 - val_loss: 0.2787 - val_accuracy: 0.9090\n",
            "Epoch 71/100\n",
            "687/692 [============================>.] - ETA: 0s - loss: 0.2054 - accuracy: 0.9228\n",
            "Epoch 71: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 7s 11ms/step - loss: 0.2054 - accuracy: 0.9228 - val_loss: 0.2787 - val_accuracy: 0.9073\n",
            "Epoch 72/100\n",
            "688/692 [============================>.] - ETA: 0s - loss: 0.2044 - accuracy: 0.9234\n",
            "Epoch 72: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2042 - accuracy: 0.9234 - val_loss: 0.2786 - val_accuracy: 0.9112\n",
            "Epoch 73/100\n",
            "687/692 [============================>.] - ETA: 0s - loss: 0.2067 - accuracy: 0.9228\n",
            "Epoch 73: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 7s 10ms/step - loss: 0.2064 - accuracy: 0.9230 - val_loss: 0.2789 - val_accuracy: 0.9122\n",
            "Epoch 74/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.2017 - accuracy: 0.9247\n",
            "Epoch 74: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2017 - accuracy: 0.9247 - val_loss: 0.2779 - val_accuracy: 0.9102\n",
            "Epoch 75/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.2045 - accuracy: 0.9244\n",
            "Epoch 75: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 9s 13ms/step - loss: 0.2045 - accuracy: 0.9244 - val_loss: 0.2797 - val_accuracy: 0.9085\n",
            "Epoch 76/100\n",
            "689/692 [============================>.] - ETA: 0s - loss: 0.2036 - accuracy: 0.9238\n",
            "Epoch 76: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 7s 11ms/step - loss: 0.2038 - accuracy: 0.9237 - val_loss: 0.2806 - val_accuracy: 0.9095\n",
            "Epoch 77/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.2022 - accuracy: 0.9248\n",
            "Epoch 77: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2022 - accuracy: 0.9248 - val_loss: 0.2807 - val_accuracy: 0.9073\n",
            "Epoch 78/100\n",
            "687/692 [============================>.] - ETA: 0s - loss: 0.2032 - accuracy: 0.9234\n",
            "Epoch 78: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 11ms/step - loss: 0.2028 - accuracy: 0.9236 - val_loss: 0.2786 - val_accuracy: 0.9080\n",
            "Epoch 79/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.2045 - accuracy: 0.9240\n",
            "Epoch 79: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 11ms/step - loss: 0.2045 - accuracy: 0.9240 - val_loss: 0.2801 - val_accuracy: 0.9083\n",
            "Epoch 80/100\n",
            "688/692 [============================>.] - ETA: 0s - loss: 0.2021 - accuracy: 0.9236\n",
            "Epoch 80: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2021 - accuracy: 0.9237 - val_loss: 0.2790 - val_accuracy: 0.9097\n",
            "Epoch 81/100\n",
            "688/692 [============================>.] - ETA: 0s - loss: 0.2005 - accuracy: 0.9239\n",
            "Epoch 81: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 11ms/step - loss: 0.2005 - accuracy: 0.9238 - val_loss: 0.2814 - val_accuracy: 0.9095\n",
            "Epoch 82/100\n",
            "689/692 [============================>.] - ETA: 0s - loss: 0.2000 - accuracy: 0.9250\n",
            "Epoch 82: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.1999 - accuracy: 0.9250 - val_loss: 0.2858 - val_accuracy: 0.9092\n",
            "Epoch 83/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.1978 - accuracy: 0.9250\n",
            "Epoch 83: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 9s 13ms/step - loss: 0.1978 - accuracy: 0.9250 - val_loss: 0.2818 - val_accuracy: 0.9115\n",
            "Epoch 84/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.1994 - accuracy: 0.9257\n",
            "Epoch 84: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 11ms/step - loss: 0.1994 - accuracy: 0.9257 - val_loss: 0.2829 - val_accuracy: 0.9105\n",
            "Epoch 85/100\n",
            "687/692 [============================>.] - ETA: 0s - loss: 0.2006 - accuracy: 0.9245\n",
            "Epoch 85: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.2002 - accuracy: 0.9247 - val_loss: 0.2818 - val_accuracy: 0.9088\n",
            "Epoch 86/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.1985 - accuracy: 0.9246\n",
            "Epoch 86: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 11ms/step - loss: 0.1985 - accuracy: 0.9246 - val_loss: 0.2853 - val_accuracy: 0.9097\n",
            "Epoch 87/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.1964 - accuracy: 0.9266\n",
            "Epoch 87: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 11ms/step - loss: 0.1963 - accuracy: 0.9266 - val_loss: 0.2846 - val_accuracy: 0.9092\n",
            "Epoch 88/100\n",
            "688/692 [============================>.] - ETA: 0s - loss: 0.1961 - accuracy: 0.9268\n",
            "Epoch 88: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.1959 - accuracy: 0.9269 - val_loss: 0.2832 - val_accuracy: 0.9097\n",
            "Epoch 89/100\n",
            "689/692 [============================>.] - ETA: 0s - loss: 0.1980 - accuracy: 0.9260\n",
            "Epoch 89: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 7s 11ms/step - loss: 0.1978 - accuracy: 0.9260 - val_loss: 0.2819 - val_accuracy: 0.9080\n",
            "Epoch 90/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.1957 - accuracy: 0.9261\n",
            "Epoch 90: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.1957 - accuracy: 0.9261 - val_loss: 0.2840 - val_accuracy: 0.9085\n",
            "Epoch 91/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.1950 - accuracy: 0.9259\n",
            "Epoch 91: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.1950 - accuracy: 0.9259 - val_loss: 0.2856 - val_accuracy: 0.9105\n",
            "Epoch 92/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.1942 - accuracy: 0.9253\n",
            "Epoch 92: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 7s 11ms/step - loss: 0.1943 - accuracy: 0.9253 - val_loss: 0.2843 - val_accuracy: 0.9092\n",
            "Epoch 93/100\n",
            "689/692 [============================>.] - ETA: 0s - loss: 0.1933 - accuracy: 0.9267\n",
            "Epoch 93: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.1932 - accuracy: 0.9269 - val_loss: 0.2847 - val_accuracy: 0.9107\n",
            "Epoch 94/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.1927 - accuracy: 0.9259\n",
            "Epoch 94: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.1927 - accuracy: 0.9259 - val_loss: 0.2853 - val_accuracy: 0.9080\n",
            "Epoch 95/100\n",
            "689/692 [============================>.] - ETA: 0s - loss: 0.1932 - accuracy: 0.9266\n",
            "Epoch 95: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 7s 11ms/step - loss: 0.1932 - accuracy: 0.9266 - val_loss: 0.2856 - val_accuracy: 0.9100\n",
            "Epoch 96/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.1907 - accuracy: 0.9273\n",
            "Epoch 96: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.1907 - accuracy: 0.9273 - val_loss: 0.2874 - val_accuracy: 0.9085\n",
            "Epoch 97/100\n",
            "689/692 [============================>.] - ETA: 0s - loss: 0.1910 - accuracy: 0.9273\n",
            "Epoch 97: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 9s 12ms/step - loss: 0.1909 - accuracy: 0.9273 - val_loss: 0.2877 - val_accuracy: 0.9107\n",
            "Epoch 98/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.1911 - accuracy: 0.9289\n",
            "Epoch 98: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 11ms/step - loss: 0.1911 - accuracy: 0.9289 - val_loss: 0.2890 - val_accuracy: 0.9095\n",
            "Epoch 99/100\n",
            "688/692 [============================>.] - ETA: 0s - loss: 0.1884 - accuracy: 0.9277\n",
            "Epoch 99: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.1887 - accuracy: 0.9277 - val_loss: 0.2893 - val_accuracy: 0.9083\n",
            "Epoch 100/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.1897 - accuracy: 0.9271\n",
            "Epoch 100: val_loss did not improve from 0.26866\n",
            "692/692 [==============================] - 8s 12ms/step - loss: 0.1896 - accuracy: 0.9272 - val_loss: 0.2887 - val_accuracy: 0.9107\n",
            "Min validation loss at epoch:  30 -> 0.26865682005882263\n",
            "136/136 [==============================] - 1s 5ms/step - loss: 0.3119 - accuracy: 0.9125\n",
            "\n",
            "Test Accuracy: 91.25%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Reshape\n",
        "\n",
        "# Build the RNN model\n",
        "units = 64\n",
        "dropout_rate = 0.2\n",
        "epochs = 100\n",
        "learn_rate = 0.0001\n",
        "num_layers = 3\n",
        "\n",
        "model = Sequential()\n",
        "for _ in range(num_layers-1):\n",
        "    model.add(Bidirectional(LSTM(units=units, return_sequences=True)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "\n",
        "model.add(Bidirectional(LSTM(units=units, return_sequences=False)))\n",
        "model.add(Dropout(dropout_rate))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=learn_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "filepath = 'best_model.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss',\n",
        "                            verbose=1, save_best_only=True, mode='min')\n",
        "callbacks = [checkpoint]\n",
        "\n",
        "\n",
        "history = model.fit(np.array(X_train_embed, dtype='float32'), y_train_onehot, epochs=epochs,\n",
        "                    validation_data=(np.array(X_dev_embed, dtype='float32'), y_dev_onehot),\n",
        "                    callbacks=callbacks, batch_size=32)\n",
        "\n",
        "loss_list = history.history['val_loss']\n",
        "print(\"Min validation loss at epoch: \", loss_list.index(min(loss_list)), \"->\", min(loss_list))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(np.array(X_test_embed), y_test_onehot)\n",
        "print(f'\\nTest Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Plot learning curves\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Calculate metrics**"
      ],
      "metadata": {
        "id": "-xBaOxtw3Ev4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def calculate_metrics(custom_model, X, y):\n",
        "  # X = X_test_embed, y = y_test_onehot\n",
        "  y_pred_class = custom_model.predict(np.array(X))\n",
        "  report = classification_report(np.argmax(y, axis=1), np.argmax(y_pred_class, axis=1), output_dict=True)\n",
        "  n_classes = y.shape[1]\n",
        "\n",
        "  # For each class\n",
        "  for i in range(n_classes):\n",
        "    precision, recall, _ = precision_recall_curve(y[:, i], y_pred_class[:, i])\n",
        "    try:\n",
        "      report[str(i)][\"pr-auc\"] = auc(recall, precision)\n",
        "    except:\n",
        "      report[str(i)] = {\"precision\": 0, \"recall\": 0, \"f1-score\": 0, \"pr-auc\": auc(recall, precision), \"support\": 0}\n",
        "\n",
        "  # A \"macro-average\": quantifying score on all classes jointly\n",
        "  precision, recall, _ = precision_recall_curve(y.ravel(), y_pred_class.ravel())\n",
        "  report[\"macro avg\"][\"pr-auc\"] = auc(recall, precision)\n",
        "  report[\"accuracy\"] = {\"precision\": '', \"recall\": '', \"f1-score\": report[\"accuracy\"], \"pr-auc\": '', \"support\": 0}\n",
        "  #del report[\"weighted avg\"]\n",
        "\n",
        "  pd.set_option('display.precision', 4)\n",
        "  final_report = pd.DataFrame.from_dict(report).T\n",
        "  final_report[\"support\"] = final_report[\"support\"].astype(int)\n",
        "  final_report = final_report.reindex(columns=[\"precision\", \"recall\", \"f1-score\", \"pr-auc\", \"support\"])\n",
        "  return final_report\n",
        "\n",
        "\n",
        "for name, X_set, y_set in zip([\"Training\", \"Development\", \"Test\"],\n",
        "                              [X_train_embed, X_dev_embed, X_test_embed],\n",
        "                              [y_train_onehot, y_dev_onehot, y_test_onehot]):\n",
        "  print(\"\\nMetrics for\", name, \"dataset:\")\n",
        "  print(calculate_metrics(model, X_set, y_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWjxzma5uy_y",
        "outputId": "614be0bb-3ba9-4930-f116-a5336ffbf255"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metrics for Training dataset:\n",
            "692/692 [==============================] - 6s 5ms/step\n",
            "             precision  recall f1-score  pr-auc  support\n",
            "0               0.9397  0.9194   0.9294  0.9834     1626\n",
            "1               0.9002  0.9026   0.9014  0.9495     2259\n",
            "2               0.9165  0.8631    0.889  0.9613      979\n",
            "3               0.8826  0.9707   0.9246  0.9665     1193\n",
            "4               0.9836     1.0   0.9917  0.9998      660\n",
            "5               0.9762  0.9712   0.9737  0.9974     1942\n",
            "6                  1.0  0.5926   0.7442  0.7979       27\n",
            "7               0.9497  0.9401   0.9449  0.9879     3491\n",
            "8               0.9543     1.0   0.9766  0.9978      313\n",
            "9               0.7049  0.9913    0.824  0.8815      576\n",
            "10              0.9673  0.8986   0.9317   0.987     1252\n",
            "11              0.9644  0.9836   0.9739  0.9962     2311\n",
            "12              0.9945  0.9996   0.9971  0.9998     2551\n",
            "13              0.6658  0.6214   0.6429  0.6732      420\n",
            "14                 0.9  0.4737   0.6207  0.6489       19\n",
            "15              0.9355  0.8664   0.8996  0.9685     2193\n",
            "16              0.9744  0.8085   0.8837  0.9667       47\n",
            "17              0.9923  0.9923   0.9923  0.9957      260\n",
            "accuracy                         0.9349                0\n",
            "macro avg       0.9223  0.8775   0.8912  0.9856    22119\n",
            "weighted avg    0.9373  0.9349   0.9349     NaN    22119\n",
            "\n",
            "Metrics for Development dataset:\n",
            "128/128 [==============================] - 1s 4ms/step\n",
            "             precision  recall f1-score  pr-auc  support\n",
            "0               0.9077  0.8632   0.8849  0.9201      285\n",
            "1               0.8903  0.9257   0.9077  0.9727      377\n",
            "2               0.8344  0.7798   0.8062  0.8916      168\n",
            "3               0.8606  0.9191   0.8889  0.9445      235\n",
            "4               0.9898    0.97   0.9798  0.9994      100\n",
            "5                0.968  0.9811   0.9745  0.9952      370\n",
            "6                  0.0     0.0      0.0  0.0061        1\n",
            "7               0.9048  0.9135   0.9091  0.9546      624\n",
            "8                0.963     1.0   0.9811  0.9961       52\n",
            "9               0.7027     1.0   0.8254   0.808      104\n",
            "10              0.9798  0.8679   0.9205  0.9788      280\n",
            "11              0.9404  0.9455   0.9429  0.9745      367\n",
            "12              0.9961     1.0   0.9981  0.9995      514\n",
            "13              0.6395  0.6548   0.6471  0.6987       84\n",
            "14                 1.0     0.6     0.75  0.6721        5\n",
            "15              0.8806  0.8213   0.8499  0.9341      431\n",
            "16                 0.0     0.0      0.0  0.0379       10\n",
            "17              0.9672     1.0   0.9833  0.9994       59\n",
            "accuracy                         0.9107                0\n",
            "macro avg       0.8014  0.7912   0.7916  0.9667     4066\n",
            "weighted avg    0.9121  0.9107   0.9101     NaN     4066\n",
            "\n",
            "Metrics for Test dataset:\n",
            "136/136 [==============================] - 1s 4ms/step\n",
            "             precision  recall f1-score  pr-auc  support\n",
            "0               0.9064  0.8914   0.8988  0.9364      304\n",
            "1                0.885  0.9106   0.8976  0.9413      414\n",
            "2               0.9042  0.8483   0.8754  0.9464      178\n",
            "3                0.915  0.9339   0.9243  0.9664      242\n",
            "4               0.9758  0.9837   0.9798  0.9991      123\n",
            "5               0.9623  0.9728   0.9675  0.9971      367\n",
            "6                  0.0     0.0      0.0  0.0947        3\n",
            "7               0.8966  0.8981   0.8974  0.9598      589\n",
            "8               0.9762  0.8454   0.9061  0.8847       97\n",
            "9               0.6712     1.0   0.8033  0.8373       98\n",
            "10              0.9303  0.8867    0.908  0.9678      256\n",
            "11              0.9423  0.9267   0.9344  0.9679      546\n",
            "12              0.9928     1.0   0.9964  0.9999      548\n",
            "13              0.7108  0.6146   0.6592  0.6979       96\n",
            "14                 1.0  0.1429     0.25  0.2274        7\n",
            "15              0.8793  0.8438   0.8612  0.9224      397\n",
            "16              0.1111     0.5   0.1818  0.1061        2\n",
            "17              0.9643     1.0   0.9818   0.979       54\n",
            "accuracy                         0.9125                0\n",
            "macro avg       0.8124  0.7888   0.7735  0.9649     4321\n",
            "weighted avg    0.9163  0.9125   0.9128     NaN     4321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Baseline Classifier and metrics**"
      ],
      "metadata": {
        "id": "PCJZHYlURzDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "\n",
        "# Flatten and extract words and POS tags\n",
        "train_flat = flatten(train_data)\n",
        "train_words, train_tags = zip(*train_flat)\n",
        "dev_flat = flatten(dev_data)\n",
        "dev_words, dev_tags = zip(*dev_flat)\n",
        "test_flat = flatten(test_data)\n",
        "test_words, test_tags = zip(*test_flat)\n",
        "\n",
        "\n",
        "class Majority_Classifier:\n",
        "  def __init__(self):\n",
        "    self.most_common_tag = None\n",
        "    self.words = []\n",
        "    self.tags = []\n",
        "    self.label_encoder = LabelEncoder()\n",
        "    self.num_classes = 0\n",
        "\n",
        "  def fit(self, training_data):\n",
        "    tag_counter = Counter(training_data)\n",
        "    self.most_common_tag = tag_counter.most_common(1)[0][0][1]\n",
        "    for word in tag_counter.keys():\n",
        "      self.words.append(word[0])\n",
        "      self.tags.append(word[1])\n",
        "\n",
        "    self.label_encoder.fit(self.tags)\n",
        "    self.num_classes = len(label_encoder.classes_)\n",
        "\n",
        "    del tag_counter\n",
        "\n",
        "  def predict(self, data):\n",
        "    data, _ = zip(*data)\n",
        "    predictions = []\n",
        "    for word in data:\n",
        "      try:\n",
        "        pred_tag = self.tags[self.words.index(word)]\n",
        "      except:\n",
        "        pred_tag = self.most_common_tag\n",
        "      predictions.append(pred_tag)\n",
        "    return to_categorical(self.label_encoder.transform(predictions), self.num_classes)\n",
        "\n",
        "majority = Majority_Classifier()\n",
        "majority.fit(train_flat)\n",
        "\n",
        "train_tags = to_categorical(majority.label_encoder.transform(train_tags), majority.num_classes)\n",
        "dev_tags = to_categorical(majority.label_encoder.transform(dev_tags), majority.num_classes)\n",
        "test_tags = to_categorical(majority.label_encoder.transform(test_tags), majority.num_classes)\n",
        "\n",
        "\n",
        "for name, X_set, y_set in zip([\"Training\", \"Development\", \"Test\"],\n",
        "                              [train_flat, dev_flat, test_flat],\n",
        "                              [train_tags, dev_tags, test_tags]):\n",
        "  print(\"\\nMetrics for\", name, \"dataset:\")\n",
        "  print(calculate_metrics(majority, X_set, y_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNif6MDvR3_R",
        "outputId": "71bfff17-b5c4-48da-b322-dd37165f69f8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metrics for Training dataset:\n",
            "             precision  recall f1-score  pr-auc  support\n",
            "0               0.9482  0.9459    0.947   0.949     1626\n",
            "1               0.9143  0.8645   0.8887  0.8964     2259\n",
            "2               0.8909   0.859   0.8747  0.8781      979\n",
            "3               0.8051  0.8692    0.836  0.8407     1193\n",
            "4               0.9939  0.9879   0.9909  0.9911      660\n",
            "5               0.9775  0.9398   0.9583  0.9613     1942\n",
            "6                 0.88  0.8148   0.8462  0.8475       27\n",
            "7               0.9659   0.957   0.9614  0.9648     3491\n",
            "8               0.9965  0.9201   0.9568  0.9589      313\n",
            "9               0.6867  0.7917   0.7355  0.7419      576\n",
            "10              0.9331  0.9137   0.9233  0.9259     1252\n",
            "11              0.9879  0.9905   0.9892  0.9897     2311\n",
            "12              0.9926     1.0   0.9963  0.9963     2551\n",
            "13              0.5245  0.6381   0.5757  0.5847      420\n",
            "14                 1.0  0.2105   0.3478  0.6056       19\n",
            "15              0.8927  0.9065   0.8995  0.9042     2193\n",
            "16                 1.0  0.9574   0.9783  0.9788       47\n",
            "17              0.9628  0.9962   0.9792  0.9795      260\n",
            "accuracy                         0.9269                0\n",
            "macro avg       0.9085  0.8646   0.8714  0.9289    22119\n",
            "weighted avg    0.9302  0.9269   0.9279     NaN    22119\n",
            "\n",
            "Metrics for Development dataset:\n",
            "             precision  recall f1-score  pr-auc  support\n",
            "0               0.9005  0.6982   0.7866  0.8099      285\n",
            "1               0.9125  0.9125   0.9125  0.9165      377\n",
            "2               0.8385  0.6488   0.7315  0.7509      168\n",
            "3               0.8353  0.8851   0.8595  0.8635      235\n",
            "4               0.9896    0.95   0.9694  0.9704      100\n",
            "5               0.3193     0.9   0.4713  0.6142      370\n",
            "6                  0.0     0.0      0.0  0.0001        1\n",
            "7               0.8958  0.5785    0.703  0.7695      624\n",
            "8                  1.0  0.5577    0.716  0.7817       52\n",
            "9               0.7719  0.8462   0.8073   0.811      104\n",
            "10              0.8849  0.8786   0.8817  0.8859      280\n",
            "11               0.982  0.4469   0.6142  0.7394      367\n",
            "12              0.9942     1.0   0.9971  0.9971      514\n",
            "13              0.5446  0.6548   0.5946  0.6032       84\n",
            "14                 1.0     0.2   0.3333  0.6005        5\n",
            "15                0.85  0.5916   0.6977  0.7425      431\n",
            "16                 0.0     0.0      0.0  0.5012       10\n",
            "17                 1.0   0.661   0.7959   0.833       59\n",
            "accuracy                         0.7477                0\n",
            "macro avg       0.7622  0.6339   0.6595  0.7547     4066\n",
            "weighted avg    0.8464  0.7477   0.7645     NaN     4066\n",
            "\n",
            "Metrics for Test dataset:\n",
            "             precision  recall f1-score  pr-auc  support\n",
            "0               0.9372  0.6875   0.7932  0.8234      304\n",
            "1               0.9144  0.8768   0.8952  0.9015      414\n",
            "2               0.8874  0.7528   0.8146  0.8252      178\n",
            "3                0.872  0.9008   0.8862  0.8892      242\n",
            "4               0.9837  0.9837   0.9837   0.984      123\n",
            "5               0.2989  0.9537   0.4551  0.6283      367\n",
            "6                  0.0     0.0      0.0  0.5003        3\n",
            "7               0.9553  0.5806   0.7223  0.7966      589\n",
            "8               0.9846  0.6598   0.7901   0.826       97\n",
            "9               0.7155  0.8469   0.7757   0.783       98\n",
            "10              0.9237  0.8984   0.9109  0.9141      256\n",
            "11              0.9698  0.4707   0.6338  0.7537      546\n",
            "12              0.9945  0.9982   0.9964  0.9965      548\n",
            "13              0.5905  0.6458   0.6169  0.6221       96\n",
            "14                 0.0     0.0      0.0  0.5008        7\n",
            "15              0.8276  0.5441   0.6565  0.7068      397\n",
            "16                 0.0     0.0      0.0  0.5002        2\n",
            "17               0.973  0.6667   0.7912  0.8219       54\n",
            "accuracy                          0.748                0\n",
            "macro avg       0.7127   0.637   0.6512   0.755     4321\n",
            "weighted avg    0.8656   0.748   0.7695     NaN     4321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}