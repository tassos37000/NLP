{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install pandas\n",
        "%pip install sklearn\n",
        "%pip install numpy\n",
        "%pip install tensorflow\n",
        "%pip install spacy"
      ],
      "metadata": {
        "id": "U6ZksfrnDoAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercise 10 with pretrained word embeding**"
      ],
      "metadata": {
        "id": "Xcb8u01PIfUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import spacy\n",
        "import requests\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, precision_recall_curve, auc, precision_recall_fscore_support\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "# Load the spaCy model with pre-trained word embeddings\n",
        "word_embeddings = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def download_and_read_data(file_url, size):\n",
        "    response = requests.get(file_url)\n",
        "    lines = response.text.splitlines()\n",
        "    sentences = []\n",
        "    current_sentence = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.startswith('#') or line == '':\n",
        "            if current_sentence:\n",
        "                sentences.append(current_sentence)\n",
        "                current_sentence = []\n",
        "                if(len(sentences) == size):\n",
        "                    break\n",
        "        else:\n",
        "            parts = line.split('\\t')\n",
        "            if len(parts) > 3:\n",
        "                current_sentence.append((parts[1], parts[3]))  # (word, pos_tag)\n",
        "    return sentences if not current_sentence else sentences + [current_sentence]\n",
        "\n",
        "# URLs\n",
        "train_url = f\"https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/master/en_ewt-ud-train.conllu\"\n",
        "dev_url = f\"https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/master/en_ewt-ud-dev.conllu\"\n",
        "test_url = f\"https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/master/en_ewt-ud-test.conllu\"\n",
        "\n",
        "# Read and preprocess data\n",
        "subset_size = 1000\n",
        "train_data = download_and_read_data(train_url, subset_size)\n",
        "dev_data = download_and_read_data(dev_url, int(subset_size/5))\n",
        "test_data = download_and_read_data(test_url, int(subset_size/5))\n",
        "\n",
        "# Extract words and POS tags\n",
        "def extract_features(sentence, i):\n",
        "    word = sentence[i][0]\n",
        "    pos = sentence[i][1]\n",
        "\n",
        "    # Features: the current word and its two neighbors\n",
        "    features = [\n",
        "        word,\n",
        "        sentence[i - 1][0] if i > 0 else '*PAD*',\n",
        "        sentence[i + 1][0] if i < len(sentence) - 1 else '*PAD*',\n",
        "    ]\n",
        "    return features, pos\n",
        "\n",
        "# Create training, development, and test datasets\n",
        "def create_dataset(data):\n",
        "    X, y = [], []\n",
        "    for sentence in data:\n",
        "        for i in range(len(sentence)):\n",
        "            features, pos = extract_features(sentence, i)\n",
        "            X.append(features)\n",
        "            y.append(pos)\n",
        "    return X, y\n",
        "\n",
        "\n",
        "X_train, y_train = create_dataset(train_data)\n",
        "X_dev, y_dev = create_dataset(dev_data)\n",
        "X_test, y_test = create_dataset(test_data)\n",
        "\n",
        "X_train_embed = []\n",
        "X_dev_embed = []\n",
        "X_test_embed = []\n",
        "\n",
        "# Convert words to spaCy word vectors\n",
        "for dataset, X_embed in zip([X_train, X_dev, X_test], [X_train_embed, X_dev_embed, X_test_embed]):\n",
        "    for sentence in tqdm.tqdm(range(len(dataset))):\n",
        "        word_vectors = [word_embeddings(word).vector for word in dataset[sentence]]\n",
        "        X_embed.append(np.array(word_vectors))\n",
        "\n",
        "\n",
        "# Encode POS tags\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "y_train_encoded = label_encoder.transform(y_train)\n",
        "y_dev_encoded = label_encoder.transform(y_dev)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "\n",
        "# Convert tags to one-hot encoding\n",
        "y_train_onehot = to_categorical(y_train_encoded, num_classes=num_classes)\n",
        "y_dev_onehot = to_categorical(y_dev_encoded, num_classes=num_classes)\n",
        "y_test_onehot = to_categorical(y_test_encoded, num_classes=num_classes)\n",
        "\n",
        "# constants\n",
        "embedding_dim = word_embeddings('test').vector.shape[0]\n",
        "max_sequence_length = 3\n",
        "\n",
        "# statistics\n",
        "print(\"Training set size:\", len(train_data))\n",
        "print(\"Development set size:\", len(dev_data))\n",
        "print(\"Test set size:\", len(test_data))\n",
        "lengths = [len(i) for i in train_data] + [len(i) for i in dev_data] + [len(i) for i in test_data]\n",
        "print(\"Average sentence length: \", sum(lengths)/len(lengths))\n",
        "words_set = set()\n",
        "for sentences in zip([train_data, dev_data, test_data]):\n",
        "    for sent in sentences:\n",
        "        for w in sent:\n",
        "            words_set.add(w[0])\n",
        "print(\"NUmber of words: \", len(words_set))\n",
        "print(\"Vocabulary size: \", len(word_embeddings.vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "De7VodcNod_d",
        "outputId": "dcf011de-04f2-468e-ac74-01064be6cf4e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22119/22119 [06:04<00:00, 60.71it/s]\n",
            "100%|██████████| 4066/4066 [01:02<00:00, 64.92it/s]\n",
            "100%|██████████| 4321/4321 [01:07<00:00, 64.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 1000\n",
            "Development set size: 200\n",
            "Test set size: 200\n",
            "Average sentence length:  21.79\n",
            "NUmber of words:  492\n",
            "Vocabulary size:  6431\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Find best hyperparameters**"
      ],
      "metadata": {
        "id": "tJVEP93SJWZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(hidden_units, dropout_rate, lr, epochs):\n",
        "  model = Sequential()\n",
        "  model.add(Flatten(input_shape=(max_sequence_length, embedding_dim)))\n",
        "  model.add(Dense(hidden_units, activation='relu'))\n",
        "  model.add(Dropout(dropout_rate))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  filepath = 'temp_best_model.hdf5'\n",
        "  checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                              monitor='val_loss',\n",
        "                              verbose=0,\n",
        "                              save_best_only=True,\n",
        "                              mode='min')\n",
        "  callbacks = [checkpoint]\n",
        "\n",
        "  history = model.fit(np.array(X_train_embed), y_train_onehot, epochs=epochs,\n",
        "                      validation_data=(np.array(X_dev_embed), y_dev_onehot),\n",
        "                      callbacks=callbacks, batch_size=32, verbose = 0)\n",
        "\n",
        "  loss, accuracy = model.evaluate(np.array(X_dev_embed), y_dev_onehot)\n",
        "  return accuracy, loss\n",
        "\n",
        "def tune_hyperparam(params):\n",
        "  best_acc = 0\n",
        "  best_loss = 100\n",
        "  best_params = ()\n",
        "  for hdu in params[\"hidden_units\"]:\n",
        "    for dro in params[\"dropout_rate\"]:\n",
        "      for lr in params[\"learning_rate\"]:\n",
        "        for ep in params[\"epochs\"]:\n",
        "          print(\"Dev accuracy for params: \", (hdu, dro, lr, ep))\n",
        "          acc, loss = evaluate_model(hdu, dro, lr, ep)\n",
        "          if loss < best_loss or (loss == best_loss and acc > best_acc):\n",
        "            best_acc = acc\n",
        "            best_loss = loss\n",
        "            best_params = (hdu, dro, lr, ep)\n",
        "\n",
        "  return best_acc, best_loss, best_params\n",
        "\n",
        "hyper_parameters = {\n",
        "    \"hidden_units\": [64, 128, 256],\n",
        "    \"dropout_rate\": [0.2, 0.4, 0.6],\n",
        "    \"learning_rate\": [0.0001, 0.001, 0.01],\n",
        "    \"epochs\": [100]\n",
        "}\n",
        "\n",
        "print(tune_hyperparam(hyper_parameters))"
      ],
      "metadata": {
        "id": "NV6wy8sa5qZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a24da4d0-c7f4-4aec-cb79-df2e09b25bd0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dev accuracy for params:  (64, 0.2, 0.0001, 100)\n",
            "128/128 [==============================] - 0s 3ms/step - loss: 0.1909 - accuracy: 0.9533\n",
            "Dev accuracy for params:  (64, 0.2, 0.001, 100)\n",
            "128/128 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.9474\n",
            "Dev accuracy for params:  (64, 0.2, 0.01, 100)\n",
            "128/128 [==============================] - 0s 3ms/step - loss: 1.4821 - accuracy: 0.9393\n",
            "Dev accuracy for params:  (64, 0.4, 0.0001, 100)\n",
            "128/128 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9533\n",
            "Dev accuracy for params:  (64, 0.4, 0.001, 100)\n",
            "128/128 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.9503\n",
            "Dev accuracy for params:  (64, 0.4, 0.01, 100)\n",
            "128/128 [==============================] - 0s 3ms/step - loss: 1.4739 - accuracy: 0.9329\n",
            "Dev accuracy for params:  (64, 0.6, 0.0001, 100)\n",
            "128/128 [==============================] - 0s 3ms/step - loss: 0.1869 - accuracy: 0.9520\n",
            "Dev accuracy for params:  (64, 0.6, 0.001, 100)\n",
            "128/128 [==============================] - 0s 2ms/step - loss: 0.3609 - accuracy: 0.9493\n",
            "Dev accuracy for params:  (64, 0.6, 0.01, 100)\n",
            "128/128 [==============================] - 1s 4ms/step - loss: 1.1970 - accuracy: 0.9188\n",
            "Dev accuracy for params:  (128, 0.2, 0.0001, 100)\n",
            "128/128 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9533\n",
            "Dev accuracy for params:  (128, 0.2, 0.001, 100)\n",
            "128/128 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.9493\n",
            "Dev accuracy for params:  (128, 0.2, 0.01, 100)\n",
            "128/128 [==============================] - 0s 3ms/step - loss: 1.7582 - accuracy: 0.9380\n",
            "Dev accuracy for params:  (128, 0.4, 0.0001, 100)\n",
            "128/128 [==============================] - 0s 3ms/step - loss: 0.2050 - accuracy: 0.9518\n",
            "Dev accuracy for params:  (128, 0.4, 0.001, 100)\n",
            "128/128 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.9520\n",
            "Dev accuracy for params:  (128, 0.4, 0.01, 100)\n",
            "128/128 [==============================] - 0s 3ms/step - loss: 1.4582 - accuracy: 0.9358\n",
            "Dev accuracy for params:  (128, 0.6, 0.0001, 100)\n",
            "128/128 [==============================] - 0s 3ms/step - loss: 0.1922 - accuracy: 0.9535\n",
            "Dev accuracy for params:  (128, 0.6, 0.001, 100)\n",
            "128/128 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.9523\n",
            "Dev accuracy for params:  (128, 0.6, 0.01, 100)\n",
            "128/128 [==============================] - 0s 3ms/step - loss: 1.4702 - accuracy: 0.9179\n",
            "Dev accuracy for params:  (256, 0.2, 0.0001, 100)\n",
            "128/128 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.9540\n",
            "Dev accuracy for params:  (256, 0.2, 0.001, 100)\n",
            "128/128 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.9508\n",
            "Dev accuracy for params:  (256, 0.2, 0.01, 100)\n",
            "128/128 [==============================] - 0s 3ms/step - loss: 2.0152 - accuracy: 0.9427\n",
            "Dev accuracy for params:  (256, 0.4, 0.0001, 100)\n",
            "128/128 [==============================] - 0s 2ms/step - loss: 0.2339 - accuracy: 0.9547\n",
            "Dev accuracy for params:  (256, 0.4, 0.001, 100)\n",
            "128/128 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.9550\n",
            "Dev accuracy for params:  (256, 0.4, 0.01, 100)\n",
            "128/128 [==============================] - 0s 4ms/step - loss: 1.9994 - accuracy: 0.9343\n",
            "Dev accuracy for params:  (256, 0.6, 0.0001, 100)\n",
            "128/128 [==============================] - 0s 3ms/step - loss: 0.2054 - accuracy: 0.9547\n",
            "Dev accuracy for params:  (256, 0.6, 0.001, 100)\n",
            "128/128 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.9540\n",
            "Dev accuracy for params:  (256, 0.6, 0.01, 100)\n",
            "128/128 [==============================] - 0s 2ms/step - loss: 1.4067 - accuracy: 0.9203\n",
            "(0.9532710313796997, 0.18487511575222015, (64, 0.4, 0.0001, 100))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build model**"
      ],
      "metadata": {
        "id": "zt0gxMc3KyS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the MLP model\n",
        "hidden_units = 64\n",
        "dropout_rate = 0.4\n",
        "epochs = 100\n",
        "learn_rate = 0.0001\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(max_sequence_length, embedding_dim)))\n",
        "model.add(Dense(hidden_units, activation='relu'))\n",
        "model.add(Dropout(dropout_rate))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=learn_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "filepath = 'best_model.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss',\n",
        "                            verbose=1, save_best_only=True, mode='min')\n",
        "callbacks = [checkpoint]\n",
        "\n",
        "\n",
        "history = model.fit(np.array(X_train_embed), y_train_onehot, epochs=epochs,\n",
        "                    validation_data=(np.array(X_dev_embed), y_dev_onehot),\n",
        "                    callbacks=callbacks, batch_size=32)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(np.array(X_test_embed), y_test_onehot)\n",
        "print(f'\\nTest Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Plot learning curves\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OBl86oTqKwq6",
        "outputId": "cfdce2de-cf84-45e8-877d-1359ea8a5190"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_31 (Flatten)        (None, 288)               0         \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 64)                18496     \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 18)                1170      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19666 (76.82 KB)\n",
            "Trainable params: 19666 (76.82 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "684/692 [============================>.] - ETA: 0s - loss: 2.0110 - accuracy: 0.4168\n",
            "Epoch 1: val_loss improved from inf to 0.93126, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 2.0026 - accuracy: 0.4196 - val_loss: 0.9313 - val_accuracy: 0.7762\n",
            "Epoch 2/100\n",
            " 50/692 [=>............................] - ETA: 2s - loss: 1.1706 - accuracy: 0.6856"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "684/692 [============================>.] - ETA: 0s - loss: 0.8773 - accuracy: 0.7556\n",
            "Epoch 2: val_loss improved from 0.93126 to 0.48383, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.8763 - accuracy: 0.7560 - val_loss: 0.4838 - val_accuracy: 0.8812\n",
            "Epoch 3/100\n",
            "677/692 [============================>.] - ETA: 0s - loss: 0.5841 - accuracy: 0.8384\n",
            "Epoch 3: val_loss improved from 0.48383 to 0.35370, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.5829 - accuracy: 0.8391 - val_loss: 0.3537 - val_accuracy: 0.9065\n",
            "Epoch 4/100\n",
            "679/692 [============================>.] - ETA: 0s - loss: 0.4528 - accuracy: 0.8720\n",
            "Epoch 4: val_loss improved from 0.35370 to 0.30021, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 2s 4ms/step - loss: 0.4522 - accuracy: 0.8724 - val_loss: 0.3002 - val_accuracy: 0.9171\n",
            "Epoch 5/100\n",
            "682/692 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.8920\n",
            "Epoch 5: val_loss improved from 0.30021 to 0.27035, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.3865 - accuracy: 0.8923 - val_loss: 0.2703 - val_accuracy: 0.9257\n",
            "Epoch 6/100\n",
            "680/692 [============================>.] - ETA: 0s - loss: 0.3507 - accuracy: 0.9004\n",
            "Epoch 6: val_loss improved from 0.27035 to 0.25205, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 2s 4ms/step - loss: 0.3498 - accuracy: 0.9007 - val_loss: 0.2521 - val_accuracy: 0.9311\n",
            "Epoch 7/100\n",
            "688/692 [============================>.] - ETA: 0s - loss: 0.3178 - accuracy: 0.9102\n",
            "Epoch 7: val_loss improved from 0.25205 to 0.24059, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.3173 - accuracy: 0.9104 - val_loss: 0.2406 - val_accuracy: 0.9329\n",
            "Epoch 8/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.2964 - accuracy: 0.9151\n",
            "Epoch 8: val_loss improved from 0.24059 to 0.22995, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.2964 - accuracy: 0.9151 - val_loss: 0.2300 - val_accuracy: 0.9353\n",
            "Epoch 9/100\n",
            "677/692 [============================>.] - ETA: 0s - loss: 0.2774 - accuracy: 0.9207\n",
            "Epoch 9: val_loss improved from 0.22995 to 0.22339, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.2775 - accuracy: 0.9210 - val_loss: 0.2234 - val_accuracy: 0.9368\n",
            "Epoch 10/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.2608 - accuracy: 0.9242\n",
            "Epoch 10: val_loss improved from 0.22339 to 0.21752, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.2608 - accuracy: 0.9242 - val_loss: 0.2175 - val_accuracy: 0.9390\n",
            "Epoch 11/100\n",
            "678/692 [============================>.] - ETA: 0s - loss: 0.2458 - accuracy: 0.9300\n",
            "Epoch 11: val_loss improved from 0.21752 to 0.21214, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.2458 - accuracy: 0.9302 - val_loss: 0.2121 - val_accuracy: 0.9383\n",
            "Epoch 12/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.2334 - accuracy: 0.9330\n",
            "Epoch 12: val_loss improved from 0.21214 to 0.20789, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.2337 - accuracy: 0.9330 - val_loss: 0.2079 - val_accuracy: 0.9397\n",
            "Epoch 13/100\n",
            "678/692 [============================>.] - ETA: 0s - loss: 0.2314 - accuracy: 0.9332\n",
            "Epoch 13: val_loss improved from 0.20789 to 0.20357, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.2316 - accuracy: 0.9332 - val_loss: 0.2036 - val_accuracy: 0.9424\n",
            "Epoch 14/100\n",
            "681/692 [============================>.] - ETA: 0s - loss: 0.2242 - accuracy: 0.9339\n",
            "Epoch 14: val_loss improved from 0.20357 to 0.20072, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 2s 4ms/step - loss: 0.2240 - accuracy: 0.9340 - val_loss: 0.2007 - val_accuracy: 0.9417\n",
            "Epoch 15/100\n",
            "676/692 [============================>.] - ETA: 0s - loss: 0.2173 - accuracy: 0.9365\n",
            "Epoch 15: val_loss improved from 0.20072 to 0.19875, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 2s 4ms/step - loss: 0.2173 - accuracy: 0.9364 - val_loss: 0.1988 - val_accuracy: 0.9427\n",
            "Epoch 16/100\n",
            "676/692 [============================>.] - ETA: 0s - loss: 0.2115 - accuracy: 0.9361\n",
            "Epoch 16: val_loss improved from 0.19875 to 0.19405, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.2107 - accuracy: 0.9363 - val_loss: 0.1940 - val_accuracy: 0.9444\n",
            "Epoch 17/100\n",
            "684/692 [============================>.] - ETA: 0s - loss: 0.2093 - accuracy: 0.9383\n",
            "Epoch 17: val_loss improved from 0.19405 to 0.19239, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.2094 - accuracy: 0.9384 - val_loss: 0.1924 - val_accuracy: 0.9454\n",
            "Epoch 18/100\n",
            "682/692 [============================>.] - ETA: 0s - loss: 0.2030 - accuracy: 0.9389\n",
            "Epoch 18: val_loss improved from 0.19239 to 0.19080, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.2028 - accuracy: 0.9391 - val_loss: 0.1908 - val_accuracy: 0.9469\n",
            "Epoch 19/100\n",
            "678/692 [============================>.] - ETA: 0s - loss: 0.1944 - accuracy: 0.9428\n",
            "Epoch 19: val_loss improved from 0.19080 to 0.18968, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 2s 4ms/step - loss: 0.1957 - accuracy: 0.9426 - val_loss: 0.1897 - val_accuracy: 0.9452\n",
            "Epoch 20/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.1923 - accuracy: 0.9426\n",
            "Epoch 20: val_loss improved from 0.18968 to 0.18862, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 2s 4ms/step - loss: 0.1924 - accuracy: 0.9426 - val_loss: 0.1886 - val_accuracy: 0.9459\n",
            "Epoch 21/100\n",
            "681/692 [============================>.] - ETA: 0s - loss: 0.1918 - accuracy: 0.9434\n",
            "Epoch 21: val_loss improved from 0.18862 to 0.18717, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1907 - accuracy: 0.9437 - val_loss: 0.1872 - val_accuracy: 0.9471\n",
            "Epoch 22/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.1837 - accuracy: 0.9454\n",
            "Epoch 22: val_loss improved from 0.18717 to 0.18667, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1836 - accuracy: 0.9454 - val_loss: 0.1867 - val_accuracy: 0.9474\n",
            "Epoch 23/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.1785 - accuracy: 0.9465\n",
            "Epoch 23: val_loss improved from 0.18667 to 0.18583, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1784 - accuracy: 0.9465 - val_loss: 0.1858 - val_accuracy: 0.9471\n",
            "Epoch 24/100\n",
            "678/692 [============================>.] - ETA: 0s - loss: 0.1764 - accuracy: 0.9469\n",
            "Epoch 24: val_loss improved from 0.18583 to 0.18485, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1768 - accuracy: 0.9467 - val_loss: 0.1849 - val_accuracy: 0.9479\n",
            "Epoch 25/100\n",
            "683/692 [============================>.] - ETA: 0s - loss: 0.1752 - accuracy: 0.9476\n",
            "Epoch 25: val_loss improved from 0.18485 to 0.18386, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1747 - accuracy: 0.9478 - val_loss: 0.1839 - val_accuracy: 0.9474\n",
            "Epoch 26/100\n",
            "687/692 [============================>.] - ETA: 0s - loss: 0.1692 - accuracy: 0.9480\n",
            "Epoch 26: val_loss improved from 0.18386 to 0.18243, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 2s 4ms/step - loss: 0.1688 - accuracy: 0.9482 - val_loss: 0.1824 - val_accuracy: 0.9479\n",
            "Epoch 27/100\n",
            "685/692 [============================>.] - ETA: 0s - loss: 0.1662 - accuracy: 0.9496\n",
            "Epoch 27: val_loss did not improve from 0.18243\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.1655 - accuracy: 0.9500 - val_loss: 0.1833 - val_accuracy: 0.9466\n",
            "Epoch 28/100\n",
            "683/692 [============================>.] - ETA: 0s - loss: 0.1643 - accuracy: 0.9509\n",
            "Epoch 28: val_loss improved from 0.18243 to 0.18104, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1639 - accuracy: 0.9511 - val_loss: 0.1810 - val_accuracy: 0.9469\n",
            "Epoch 29/100\n",
            "684/692 [============================>.] - ETA: 0s - loss: 0.1573 - accuracy: 0.9518\n",
            "Epoch 29: val_loss did not improve from 0.18104\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1574 - accuracy: 0.9518 - val_loss: 0.1813 - val_accuracy: 0.9461\n",
            "Epoch 30/100\n",
            "688/692 [============================>.] - ETA: 0s - loss: 0.1599 - accuracy: 0.9510\n",
            "Epoch 30: val_loss did not improve from 0.18104\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1596 - accuracy: 0.9510 - val_loss: 0.1818 - val_accuracy: 0.9486\n",
            "Epoch 31/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.1536 - accuracy: 0.9534\n",
            "Epoch 31: val_loss did not improve from 0.18104\n",
            "692/692 [==============================] - 2s 4ms/step - loss: 0.1535 - accuracy: 0.9535 - val_loss: 0.1816 - val_accuracy: 0.9493\n",
            "Epoch 32/100\n",
            "686/692 [============================>.] - ETA: 0s - loss: 0.1533 - accuracy: 0.9534\n",
            "Epoch 32: val_loss improved from 0.18104 to 0.17959, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1535 - accuracy: 0.9535 - val_loss: 0.1796 - val_accuracy: 0.9486\n",
            "Epoch 33/100\n",
            "684/692 [============================>.] - ETA: 0s - loss: 0.1552 - accuracy: 0.9531\n",
            "Epoch 33: val_loss did not improve from 0.17959\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1549 - accuracy: 0.9532 - val_loss: 0.1804 - val_accuracy: 0.9493\n",
            "Epoch 34/100\n",
            "677/692 [============================>.] - ETA: 0s - loss: 0.1513 - accuracy: 0.9533\n",
            "Epoch 34: val_loss improved from 0.17959 to 0.17944, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1522 - accuracy: 0.9528 - val_loss: 0.1794 - val_accuracy: 0.9496\n",
            "Epoch 35/100\n",
            "676/692 [============================>.] - ETA: 0s - loss: 0.1485 - accuracy: 0.9554\n",
            "Epoch 35: val_loss improved from 0.17944 to 0.17890, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 2s 4ms/step - loss: 0.1480 - accuracy: 0.9553 - val_loss: 0.1789 - val_accuracy: 0.9493\n",
            "Epoch 36/100\n",
            "682/692 [============================>.] - ETA: 0s - loss: 0.1459 - accuracy: 0.9550\n",
            "Epoch 36: val_loss did not improve from 0.17890\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1453 - accuracy: 0.9552 - val_loss: 0.1799 - val_accuracy: 0.9493\n",
            "Epoch 37/100\n",
            "686/692 [============================>.] - ETA: 0s - loss: 0.1435 - accuracy: 0.9548\n",
            "Epoch 37: val_loss improved from 0.17890 to 0.17847, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.1433 - accuracy: 0.9548 - val_loss: 0.1785 - val_accuracy: 0.9503\n",
            "Epoch 38/100\n",
            "676/692 [============================>.] - ETA: 0s - loss: 0.1435 - accuracy: 0.9557\n",
            "Epoch 38: val_loss did not improve from 0.17847\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1433 - accuracy: 0.9557 - val_loss: 0.1788 - val_accuracy: 0.9481\n",
            "Epoch 39/100\n",
            "686/692 [============================>.] - ETA: 0s - loss: 0.1407 - accuracy: 0.9565\n",
            "Epoch 39: val_loss improved from 0.17847 to 0.17721, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1404 - accuracy: 0.9566 - val_loss: 0.1772 - val_accuracy: 0.9501\n",
            "Epoch 40/100\n",
            "680/692 [============================>.] - ETA: 0s - loss: 0.1383 - accuracy: 0.9576\n",
            "Epoch 40: val_loss did not improve from 0.17721\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1382 - accuracy: 0.9575 - val_loss: 0.1778 - val_accuracy: 0.9491\n",
            "Epoch 41/100\n",
            "682/692 [============================>.] - ETA: 0s - loss: 0.1359 - accuracy: 0.9577\n",
            "Epoch 41: val_loss did not improve from 0.17721\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1357 - accuracy: 0.9578 - val_loss: 0.1784 - val_accuracy: 0.9508\n",
            "Epoch 42/100\n",
            "686/692 [============================>.] - ETA: 0s - loss: 0.1369 - accuracy: 0.9580\n",
            "Epoch 42: val_loss improved from 0.17721 to 0.17598, saving model to best_model.hdf5\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.1371 - accuracy: 0.9580 - val_loss: 0.1760 - val_accuracy: 0.9498\n",
            "Epoch 43/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.1343 - accuracy: 0.9581\n",
            "Epoch 43: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1346 - accuracy: 0.9580 - val_loss: 0.1784 - val_accuracy: 0.9503\n",
            "Epoch 44/100\n",
            "688/692 [============================>.] - ETA: 0s - loss: 0.1335 - accuracy: 0.9578\n",
            "Epoch 44: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1335 - accuracy: 0.9579 - val_loss: 0.1782 - val_accuracy: 0.9491\n",
            "Epoch 45/100\n",
            "682/692 [============================>.] - ETA: 0s - loss: 0.1288 - accuracy: 0.9598\n",
            "Epoch 45: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 2s 4ms/step - loss: 0.1287 - accuracy: 0.9599 - val_loss: 0.1789 - val_accuracy: 0.9488\n",
            "Epoch 46/100\n",
            "679/692 [============================>.] - ETA: 0s - loss: 0.1282 - accuracy: 0.9597\n",
            "Epoch 46: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1283 - accuracy: 0.9598 - val_loss: 0.1786 - val_accuracy: 0.9506\n",
            "Epoch 47/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.1285 - accuracy: 0.9610\n",
            "Epoch 47: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.1286 - accuracy: 0.9610 - val_loss: 0.1772 - val_accuracy: 0.9498\n",
            "Epoch 48/100\n",
            "678/692 [============================>.] - ETA: 0s - loss: 0.1278 - accuracy: 0.9604\n",
            "Epoch 48: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1274 - accuracy: 0.9605 - val_loss: 0.1787 - val_accuracy: 0.9503\n",
            "Epoch 49/100\n",
            "686/692 [============================>.] - ETA: 0s - loss: 0.1245 - accuracy: 0.9619\n",
            "Epoch 49: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1244 - accuracy: 0.9620 - val_loss: 0.1777 - val_accuracy: 0.9506\n",
            "Epoch 50/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.1235 - accuracy: 0.9623\n",
            "Epoch 50: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1234 - accuracy: 0.9623 - val_loss: 0.1780 - val_accuracy: 0.9493\n",
            "Epoch 51/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.1229 - accuracy: 0.9617\n",
            "Epoch 51: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1229 - accuracy: 0.9617 - val_loss: 0.1780 - val_accuracy: 0.9508\n",
            "Epoch 52/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.1215 - accuracy: 0.9619\n",
            "Epoch 52: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.1214 - accuracy: 0.9619 - val_loss: 0.1765 - val_accuracy: 0.9491\n",
            "Epoch 53/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.1189 - accuracy: 0.9624\n",
            "Epoch 53: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1187 - accuracy: 0.9625 - val_loss: 0.1800 - val_accuracy: 0.9513\n",
            "Epoch 54/100\n",
            "682/692 [============================>.] - ETA: 0s - loss: 0.1163 - accuracy: 0.9638\n",
            "Epoch 54: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1168 - accuracy: 0.9637 - val_loss: 0.1788 - val_accuracy: 0.9506\n",
            "Epoch 55/100\n",
            "676/692 [============================>.] - ETA: 0s - loss: 0.1170 - accuracy: 0.9622\n",
            "Epoch 55: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 2s 4ms/step - loss: 0.1166 - accuracy: 0.9624 - val_loss: 0.1783 - val_accuracy: 0.9506\n",
            "Epoch 56/100\n",
            "684/692 [============================>.] - ETA: 0s - loss: 0.1194 - accuracy: 0.9618\n",
            "Epoch 56: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 2s 4ms/step - loss: 0.1190 - accuracy: 0.9621 - val_loss: 0.1779 - val_accuracy: 0.9513\n",
            "Epoch 57/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.1168 - accuracy: 0.9644\n",
            "Epoch 57: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.1170 - accuracy: 0.9644 - val_loss: 0.1781 - val_accuracy: 0.9503\n",
            "Epoch 58/100\n",
            "681/692 [============================>.] - ETA: 0s - loss: 0.1140 - accuracy: 0.9645\n",
            "Epoch 58: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1141 - accuracy: 0.9646 - val_loss: 0.1786 - val_accuracy: 0.9508\n",
            "Epoch 59/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.1108 - accuracy: 0.9661\n",
            "Epoch 59: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1112 - accuracy: 0.9660 - val_loss: 0.1784 - val_accuracy: 0.9498\n",
            "Epoch 60/100\n",
            "689/692 [============================>.] - ETA: 0s - loss: 0.1137 - accuracy: 0.9643\n",
            "Epoch 60: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1136 - accuracy: 0.9643 - val_loss: 0.1791 - val_accuracy: 0.9498\n",
            "Epoch 61/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.1117 - accuracy: 0.9649\n",
            "Epoch 61: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 2s 4ms/step - loss: 0.1117 - accuracy: 0.9649 - val_loss: 0.1794 - val_accuracy: 0.9503\n",
            "Epoch 62/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.1109 - accuracy: 0.9650\n",
            "Epoch 62: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1109 - accuracy: 0.9650 - val_loss: 0.1801 - val_accuracy: 0.9491\n",
            "Epoch 63/100\n",
            "683/692 [============================>.] - ETA: 0s - loss: 0.1081 - accuracy: 0.9654\n",
            "Epoch 63: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1080 - accuracy: 0.9655 - val_loss: 0.1803 - val_accuracy: 0.9498\n",
            "Epoch 64/100\n",
            "686/692 [============================>.] - ETA: 0s - loss: 0.1082 - accuracy: 0.9660\n",
            "Epoch 64: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1077 - accuracy: 0.9662 - val_loss: 0.1811 - val_accuracy: 0.9501\n",
            "Epoch 65/100\n",
            "685/692 [============================>.] - ETA: 0s - loss: 0.1076 - accuracy: 0.9662\n",
            "Epoch 65: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1075 - accuracy: 0.9662 - val_loss: 0.1816 - val_accuracy: 0.9513\n",
            "Epoch 66/100\n",
            "679/692 [============================>.] - ETA: 0s - loss: 0.1079 - accuracy: 0.9661\n",
            "Epoch 66: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 2s 4ms/step - loss: 0.1073 - accuracy: 0.9662 - val_loss: 0.1803 - val_accuracy: 0.9515\n",
            "Epoch 67/100\n",
            "684/692 [============================>.] - ETA: 0s - loss: 0.1062 - accuracy: 0.9653\n",
            "Epoch 67: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.1064 - accuracy: 0.9651 - val_loss: 0.1818 - val_accuracy: 0.9511\n",
            "Epoch 68/100\n",
            "678/692 [============================>.] - ETA: 0s - loss: 0.1026 - accuracy: 0.9676\n",
            "Epoch 68: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.1030 - accuracy: 0.9674 - val_loss: 0.1810 - val_accuracy: 0.9515\n",
            "Epoch 69/100\n",
            "677/692 [============================>.] - ETA: 0s - loss: 0.1042 - accuracy: 0.9669\n",
            "Epoch 69: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1047 - accuracy: 0.9667 - val_loss: 0.1819 - val_accuracy: 0.9498\n",
            "Epoch 70/100\n",
            "685/692 [============================>.] - ETA: 0s - loss: 0.1044 - accuracy: 0.9657\n",
            "Epoch 70: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1047 - accuracy: 0.9656 - val_loss: 0.1819 - val_accuracy: 0.9513\n",
            "Epoch 71/100\n",
            "681/692 [============================>.] - ETA: 0s - loss: 0.1020 - accuracy: 0.9667\n",
            "Epoch 71: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 2s 4ms/step - loss: 0.1019 - accuracy: 0.9667 - val_loss: 0.1822 - val_accuracy: 0.9518\n",
            "Epoch 72/100\n",
            "681/692 [============================>.] - ETA: 0s - loss: 0.1042 - accuracy: 0.9673\n",
            "Epoch 72: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.1041 - accuracy: 0.9673 - val_loss: 0.1818 - val_accuracy: 0.9508\n",
            "Epoch 73/100\n",
            "678/692 [============================>.] - ETA: 0s - loss: 0.0997 - accuracy: 0.9688\n",
            "Epoch 73: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.0997 - accuracy: 0.9689 - val_loss: 0.1815 - val_accuracy: 0.9513\n",
            "Epoch 74/100\n",
            "688/692 [============================>.] - ETA: 0s - loss: 0.1011 - accuracy: 0.9680\n",
            "Epoch 74: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 2s 4ms/step - loss: 0.1008 - accuracy: 0.9682 - val_loss: 0.1840 - val_accuracy: 0.9525\n",
            "Epoch 75/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.0977 - accuracy: 0.9694\n",
            "Epoch 75: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.0981 - accuracy: 0.9692 - val_loss: 0.1819 - val_accuracy: 0.9511\n",
            "Epoch 76/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.0985 - accuracy: 0.9677\n",
            "Epoch 76: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.0985 - accuracy: 0.9677 - val_loss: 0.1845 - val_accuracy: 0.9506\n",
            "Epoch 77/100\n",
            "688/692 [============================>.] - ETA: 0s - loss: 0.0978 - accuracy: 0.9677\n",
            "Epoch 77: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0975 - accuracy: 0.9678 - val_loss: 0.1846 - val_accuracy: 0.9506\n",
            "Epoch 78/100\n",
            "692/692 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9698\n",
            "Epoch 78: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0948 - accuracy: 0.9698 - val_loss: 0.1833 - val_accuracy: 0.9515\n",
            "Epoch 79/100\n",
            "690/692 [============================>.] - ETA: 0s - loss: 0.0959 - accuracy: 0.9690\n",
            "Epoch 79: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.0960 - accuracy: 0.9689 - val_loss: 0.1864 - val_accuracy: 0.9508\n",
            "Epoch 80/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.0951 - accuracy: 0.9693\n",
            "Epoch 80: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.0953 - accuracy: 0.9692 - val_loss: 0.1856 - val_accuracy: 0.9513\n",
            "Epoch 81/100\n",
            "680/692 [============================>.] - ETA: 0s - loss: 0.0929 - accuracy: 0.9703\n",
            "Epoch 81: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.0929 - accuracy: 0.9704 - val_loss: 0.1848 - val_accuracy: 0.9523\n",
            "Epoch 82/100\n",
            "687/692 [============================>.] - ETA: 0s - loss: 0.0972 - accuracy: 0.9693\n",
            "Epoch 82: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0972 - accuracy: 0.9693 - val_loss: 0.1854 - val_accuracy: 0.9513\n",
            "Epoch 83/100\n",
            "682/692 [============================>.] - ETA: 0s - loss: 0.0913 - accuracy: 0.9692\n",
            "Epoch 83: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.0925 - accuracy: 0.9691 - val_loss: 0.1860 - val_accuracy: 0.9506\n",
            "Epoch 84/100\n",
            "677/692 [============================>.] - ETA: 0s - loss: 0.0929 - accuracy: 0.9711\n",
            "Epoch 84: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.0923 - accuracy: 0.9713 - val_loss: 0.1862 - val_accuracy: 0.9513\n",
            "Epoch 85/100\n",
            "681/692 [============================>.] - ETA: 0s - loss: 0.0915 - accuracy: 0.9705\n",
            "Epoch 85: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 2s 4ms/step - loss: 0.0913 - accuracy: 0.9705 - val_loss: 0.1861 - val_accuracy: 0.9518\n",
            "Epoch 86/100\n",
            "684/692 [============================>.] - ETA: 0s - loss: 0.0892 - accuracy: 0.9712\n",
            "Epoch 86: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 2s 4ms/step - loss: 0.0896 - accuracy: 0.9712 - val_loss: 0.1875 - val_accuracy: 0.9515\n",
            "Epoch 87/100\n",
            "682/692 [============================>.] - ETA: 0s - loss: 0.0894 - accuracy: 0.9710\n",
            "Epoch 87: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0891 - accuracy: 0.9712 - val_loss: 0.1873 - val_accuracy: 0.9528\n",
            "Epoch 88/100\n",
            "691/692 [============================>.] - ETA: 0s - loss: 0.0903 - accuracy: 0.9712\n",
            "Epoch 88: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.0903 - accuracy: 0.9712 - val_loss: 0.1862 - val_accuracy: 0.9520\n",
            "Epoch 89/100\n",
            "679/692 [============================>.] - ETA: 0s - loss: 0.0869 - accuracy: 0.9721\n",
            "Epoch 89: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.0867 - accuracy: 0.9723 - val_loss: 0.1892 - val_accuracy: 0.9513\n",
            "Epoch 90/100\n",
            "689/692 [============================>.] - ETA: 0s - loss: 0.0905 - accuracy: 0.9702\n",
            "Epoch 90: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.0905 - accuracy: 0.9703 - val_loss: 0.1886 - val_accuracy: 0.9515\n",
            "Epoch 91/100\n",
            "680/692 [============================>.] - ETA: 0s - loss: 0.0888 - accuracy: 0.9711\n",
            "Epoch 91: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.0890 - accuracy: 0.9711 - val_loss: 0.1894 - val_accuracy: 0.9501\n",
            "Epoch 92/100\n",
            "685/692 [============================>.] - ETA: 0s - loss: 0.0892 - accuracy: 0.9714\n",
            "Epoch 92: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 4s 5ms/step - loss: 0.0892 - accuracy: 0.9715 - val_loss: 0.1894 - val_accuracy: 0.9508\n",
            "Epoch 93/100\n",
            "680/692 [============================>.] - ETA: 0s - loss: 0.0857 - accuracy: 0.9733\n",
            "Epoch 93: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.0853 - accuracy: 0.9734 - val_loss: 0.1914 - val_accuracy: 0.9503\n",
            "Epoch 94/100\n",
            "683/692 [============================>.] - ETA: 0s - loss: 0.0874 - accuracy: 0.9710\n",
            "Epoch 94: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.0876 - accuracy: 0.9709 - val_loss: 0.1925 - val_accuracy: 0.9508\n",
            "Epoch 95/100\n",
            "687/692 [============================>.] - ETA: 0s - loss: 0.0858 - accuracy: 0.9726\n",
            "Epoch 95: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.0856 - accuracy: 0.9726 - val_loss: 0.1898 - val_accuracy: 0.9508\n",
            "Epoch 96/100\n",
            "686/692 [============================>.] - ETA: 0s - loss: 0.0881 - accuracy: 0.9718\n",
            "Epoch 96: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.0881 - accuracy: 0.9717 - val_loss: 0.1921 - val_accuracy: 0.9511\n",
            "Epoch 97/100\n",
            "686/692 [============================>.] - ETA: 0s - loss: 0.0837 - accuracy: 0.9733\n",
            "Epoch 97: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 5ms/step - loss: 0.0840 - accuracy: 0.9732 - val_loss: 0.1920 - val_accuracy: 0.9508\n",
            "Epoch 98/100\n",
            "687/692 [============================>.] - ETA: 0s - loss: 0.0830 - accuracy: 0.9731\n",
            "Epoch 98: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.0828 - accuracy: 0.9731 - val_loss: 0.1929 - val_accuracy: 0.9518\n",
            "Epoch 99/100\n",
            "677/692 [============================>.] - ETA: 0s - loss: 0.0857 - accuracy: 0.9719\n",
            "Epoch 99: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.0852 - accuracy: 0.9721 - val_loss: 0.1932 - val_accuracy: 0.9520\n",
            "Epoch 100/100\n",
            "680/692 [============================>.] - ETA: 0s - loss: 0.0823 - accuracy: 0.9735\n",
            "Epoch 100: val_loss did not improve from 0.17598\n",
            "692/692 [==============================] - 3s 4ms/step - loss: 0.0822 - accuracy: 0.9736 - val_loss: 0.1952 - val_accuracy: 0.9511\n",
            "136/136 [==============================] - 0s 3ms/step - loss: 0.2179 - accuracy: 0.9530\n",
            "\n",
            "Test Accuracy: 95.30%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list = history.history['val_loss']\n",
        "print(\"Min validation loss at epoch: \", loss_list.index(min(loss_list)), \"->\", min(loss_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwotcx_a2XoV",
        "outputId": "b032f550-cb95-498a-9bc7-2456794ee628"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min validation loss at epoch:  41 -> 0.17597517371177673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Calculate metrics for MLP**"
      ],
      "metadata": {
        "id": "zAa4B32nJ3Mr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def calculate_metrics(custom_model, X, y):\n",
        "  # X = X_test_embed, y = y_test_onehot\n",
        "  y_pred_class = custom_model.predict(np.array(X))\n",
        "  report = classification_report(np.argmax(y, axis=1), np.argmax(y_pred_class, axis=1), output_dict=True)\n",
        "  n_classes = y.shape[1]\n",
        "\n",
        "  # For each class\n",
        "  for i in range(n_classes):\n",
        "    precision, recall, _ = precision_recall_curve(y[:, i], y_pred_class[:, i])\n",
        "    try:\n",
        "      report[str(i)][\"pr-auc\"] = auc(recall, precision)\n",
        "    except:\n",
        "      report[str(i)] = {\"precision\": 0, \"recall\": 0, \"f1-score\": 0, \"pr-auc\": auc(recall, precision), \"support\": 0}\n",
        "\n",
        "  # A \"macro-average\": quantifying score on all classes jointly\n",
        "  precision, recall, _ = precision_recall_curve(y.ravel(), y_pred_class.ravel())\n",
        "  report[\"macro avg\"][\"pr-auc\"] = auc(recall, precision)\n",
        "  report[\"accuracy\"] = {\"precision\": '', \"recall\": '', \"f1-score\": report[\"accuracy\"], \"pr-auc\": '', \"support\": 0}\n",
        "  #del report[\"weighted avg\"]\n",
        "\n",
        "  pd.set_option('display.precision', 4)\n",
        "  final_report = pd.DataFrame.from_dict(report).T\n",
        "  final_report[\"support\"] = final_report[\"support\"].astype(int)\n",
        "  final_report = final_report.reindex(columns=[\"precision\", \"recall\", \"f1-score\", \"pr-auc\", \"support\"])\n",
        "  return final_report\n",
        "\n",
        "\n",
        "for name, X_set, y_set in zip([\"Training\", \"Development\", \"Test\"],\n",
        "                              [X_train_embed, X_dev_embed, X_test_embed],\n",
        "                              [y_train_onehot, y_dev_onehot, y_test_onehot]):\n",
        "  print(\"\\nMetrics for\", name, \"dataset:\")\n",
        "  print(calculate_metrics(model, X_set, y_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ocauH-_ZjwE",
        "outputId": "cbb6f677-16db-402f-f5b9-5d454c60edf6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metrics for Training dataset:\n",
            "692/692 [==============================] - 1s 2ms/step\n",
            "             precision  recall f1-score  pr-auc  support\n",
            "0               0.9782  0.9674   0.9728  0.9953     1626\n",
            "1               0.9791  0.9947   0.9868  0.9992     2259\n",
            "2               0.9928  0.9796   0.9861  0.9981      979\n",
            "3               0.9967  0.9992   0.9979  0.9999     1193\n",
            "4               0.9985     1.0   0.9992     1.0      660\n",
            "5                0.999   0.999    0.999     1.0     1942\n",
            "6                  1.0  0.7407   0.8511  0.9123       27\n",
            "7               0.9816  0.9759   0.9787  0.9972     3491\n",
            "8               0.9968  0.9968   0.9968  0.9999      313\n",
            "9               0.9983     1.0   0.9991     1.0      576\n",
            "10              0.9976  0.9936   0.9956  0.9999     1252\n",
            "11              0.9624  0.9844   0.9733  0.9952     2311\n",
            "12              0.9996  0.9996   0.9996     1.0     2551\n",
            "13               0.972  0.9095   0.9397  0.9859      420\n",
            "14                 1.0  0.9474    0.973     1.0       19\n",
            "15              0.9863  0.9872   0.9868  0.9988     2193\n",
            "16              0.9524  0.8511   0.8989  0.9512       47\n",
            "17              0.9962  0.9962   0.9962  0.9999      260\n",
            "accuracy                         0.9864                0\n",
            "macro avg       0.9882  0.9623   0.9739  0.9987    22119\n",
            "weighted avg    0.9865  0.9864   0.9864     NaN    22119\n",
            "\n",
            "Metrics for Development dataset:\n",
            "128/128 [==============================] - 0s 2ms/step\n",
            "             precision  recall f1-score  pr-auc  support\n",
            "0               0.9041  0.9263   0.9151  0.9625      285\n",
            "1               0.9291  0.9735   0.9508  0.9896      377\n",
            "2               0.9032  0.8333   0.8669  0.9352      168\n",
            "3               0.9746  0.9787   0.9766  0.9962      235\n",
            "4                  1.0    0.96   0.9796  0.9975      100\n",
            "5               0.9839  0.9919   0.9879  0.9985      370\n",
            "6                  0.0     0.0      0.0  0.0005        1\n",
            "7               0.9282  0.9535   0.9407   0.975      624\n",
            "8               0.9811     1.0   0.9905     1.0       52\n",
            "9               0.9899  0.9423   0.9655  0.9961      104\n",
            "10              0.9891  0.9679   0.9783  0.9979      280\n",
            "11              0.9383  0.9537   0.9459  0.9801      367\n",
            "12              0.9922  0.9961   0.9942  0.9975      514\n",
            "13              0.8462  0.7857   0.8148  0.8874       84\n",
            "14                 1.0     0.2   0.3333  0.3844        5\n",
            "15              0.9433  0.9258   0.9344  0.9768      431\n",
            "16                 0.0     0.0      0.0  0.0359       10\n",
            "17                 1.0     1.0      1.0     1.0       59\n",
            "accuracy                         0.9511                0\n",
            "macro avg       0.8502  0.7994   0.8097  0.9847     4066\n",
            "weighted avg    0.9491  0.9511   0.9495     NaN     4066\n",
            "\n",
            "Metrics for Test dataset:\n",
            "136/136 [==============================] - 0s 2ms/step\n",
            "             precision  recall f1-score  pr-auc  support\n",
            "0               0.8997  0.9145    0.907  0.9618      304\n",
            "1                0.946  0.9734   0.9595  0.9808      414\n",
            "2               0.9249  0.8989   0.9117  0.9658      178\n",
            "3               0.9835  0.9835   0.9835   0.994      242\n",
            "4               0.9918  0.9837   0.9878  0.9976      123\n",
            "5               0.9864  0.9918   0.9891  0.9996      367\n",
            "6                  1.0  0.6667      0.8  0.6675        3\n",
            "7                0.953  0.9287   0.9407  0.9806      589\n",
            "8                0.975  0.8041   0.8814  0.8925       97\n",
            "9               0.9792  0.9592   0.9691  0.9972       98\n",
            "10              0.9506  0.9766   0.9634  0.9845      256\n",
            "11              0.9224  0.9579   0.9398  0.9708      546\n",
            "12              0.9946     1.0   0.9973     1.0      548\n",
            "13              0.8977  0.8229   0.8587  0.9045       96\n",
            "14                 1.0  0.1429     0.25  0.3394        7\n",
            "15              0.9401  0.9496   0.9449  0.9847      397\n",
            "16                 1.0     0.5   0.6667  0.7083        2\n",
            "17              0.9643     1.0   0.9818  0.9975       54\n",
            "accuracy                          0.953                0\n",
            "macro avg       0.9616  0.8586   0.8851  0.9842     4321\n",
            "weighted avg    0.9533   0.953   0.9522     NaN     4321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Baseline Classifier and metrics**"
      ],
      "metadata": {
        "id": "P4rNXcKNJ9h8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "\n",
        "# Flatten and extract words and POS tags\n",
        "train_flat = flatten(train_data)\n",
        "train_words, train_tags = zip(*train_flat)\n",
        "dev_flat = flatten(dev_data)\n",
        "dev_words, dev_tags = zip(*dev_flat)\n",
        "test_flat = flatten(test_data)\n",
        "test_words, test_tags = zip(*test_flat)\n",
        "\n",
        "\n",
        "class Majority_Classifier:\n",
        "  def __init__(self):\n",
        "    self.most_common_tag = None\n",
        "    self.words = []\n",
        "    self.tags = []\n",
        "    self.label_encoder = LabelEncoder()\n",
        "    self.num_classes = 0\n",
        "\n",
        "  def fit(self, training_data):\n",
        "    tag_counter = Counter(training_data)\n",
        "    self.most_common_tag = tag_counter.most_common(1)[0][0][1]\n",
        "    for word in tag_counter.keys():\n",
        "      self.words.append(word[0])\n",
        "      self.tags.append(word[1])\n",
        "\n",
        "    self.label_encoder.fit(self.tags)\n",
        "    self.num_classes = len(label_encoder.classes_)\n",
        "\n",
        "    del tag_counter\n",
        "\n",
        "  def predict(self, data):\n",
        "    data, _ = zip(*data)\n",
        "    predictions = []\n",
        "    for word in data:\n",
        "      try:\n",
        "        pred_tag = self.tags[self.words.index(word)]\n",
        "      except:\n",
        "        pred_tag = self.most_common_tag\n",
        "      predictions.append(pred_tag)\n",
        "    return to_categorical(self.label_encoder.transform(predictions), self.num_classes)\n",
        "\n",
        "majority = Majority_Classifier()\n",
        "majority.fit(train_flat)\n",
        "\n",
        "train_tags = to_categorical(majority.label_encoder.transform(train_tags), majority.num_classes)\n",
        "dev_tags = to_categorical(majority.label_encoder.transform(dev_tags), majority.num_classes)\n",
        "test_tags = to_categorical(majority.label_encoder.transform(test_tags), majority.num_classes)\n",
        "\n",
        "\n",
        "for name, X_set, y_set in zip([\"Training\", \"Development\", \"Test\"],\n",
        "                              [train_flat, dev_flat, test_flat],\n",
        "                              [train_tags, dev_tags, test_tags]):\n",
        "  print(\"\\nMetrics for\", name, \"dataset:\")\n",
        "  print(calculate_metrics(majority, X_set, y_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lenZIvo3c9PV",
        "outputId": "a0477705-86cc-4317-c2cc-974d87dc773a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metrics for Training dataset:\n",
            "             precision  recall f1-score  pr-auc  support\n",
            "0               0.9482  0.9459    0.947   0.949     1626\n",
            "1               0.9143  0.8645   0.8887  0.8964     2259\n",
            "2               0.8909   0.859   0.8747  0.8781      979\n",
            "3               0.8051  0.8692    0.836  0.8407     1193\n",
            "4               0.9939  0.9879   0.9909  0.9911      660\n",
            "5               0.9775  0.9398   0.9583  0.9613     1942\n",
            "6                 0.88  0.8148   0.8462  0.8475       27\n",
            "7               0.9659   0.957   0.9614  0.9648     3491\n",
            "8               0.9965  0.9201   0.9568  0.9589      313\n",
            "9               0.6867  0.7917   0.7355  0.7419      576\n",
            "10              0.9331  0.9137   0.9233  0.9259     1252\n",
            "11              0.9879  0.9905   0.9892  0.9897     2311\n",
            "12              0.9926     1.0   0.9963  0.9963     2551\n",
            "13              0.5245  0.6381   0.5757  0.5847      420\n",
            "14                 1.0  0.2105   0.3478  0.6056       19\n",
            "15              0.8927  0.9065   0.8995  0.9042     2193\n",
            "16                 1.0  0.9574   0.9783  0.9788       47\n",
            "17              0.9628  0.9962   0.9792  0.9795      260\n",
            "accuracy                         0.9269                0\n",
            "macro avg       0.9085  0.8646   0.8714  0.9289    22119\n",
            "weighted avg    0.9302  0.9269   0.9279     NaN    22119\n",
            "\n",
            "Metrics for Development dataset:\n",
            "             precision  recall f1-score  pr-auc  support\n",
            "0               0.9005  0.6982   0.7866  0.8099      285\n",
            "1               0.9125  0.9125   0.9125  0.9165      377\n",
            "2               0.8385  0.6488   0.7315  0.7509      168\n",
            "3               0.8353  0.8851   0.8595  0.8635      235\n",
            "4               0.9896    0.95   0.9694  0.9704      100\n",
            "5               0.3193     0.9   0.4713  0.6142      370\n",
            "6                  0.0     0.0      0.0  0.0001        1\n",
            "7               0.8958  0.5785    0.703  0.7695      624\n",
            "8                  1.0  0.5577    0.716  0.7817       52\n",
            "9               0.7719  0.8462   0.8073   0.811      104\n",
            "10              0.8849  0.8786   0.8817  0.8859      280\n",
            "11               0.982  0.4469   0.6142  0.7394      367\n",
            "12              0.9942     1.0   0.9971  0.9971      514\n",
            "13              0.5446  0.6548   0.5946  0.6032       84\n",
            "14                 1.0     0.2   0.3333  0.6005        5\n",
            "15                0.85  0.5916   0.6977  0.7425      431\n",
            "16                 0.0     0.0      0.0  0.5012       10\n",
            "17                 1.0   0.661   0.7959   0.833       59\n",
            "accuracy                         0.7477                0\n",
            "macro avg       0.7622  0.6339   0.6595  0.7547     4066\n",
            "weighted avg    0.8464  0.7477   0.7645     NaN     4066\n",
            "\n",
            "Metrics for Test dataset:\n",
            "             precision  recall f1-score  pr-auc  support\n",
            "0               0.9372  0.6875   0.7932  0.8234      304\n",
            "1               0.9144  0.8768   0.8952  0.9015      414\n",
            "2               0.8874  0.7528   0.8146  0.8252      178\n",
            "3                0.872  0.9008   0.8862  0.8892      242\n",
            "4               0.9837  0.9837   0.9837   0.984      123\n",
            "5               0.2989  0.9537   0.4551  0.6283      367\n",
            "6                  0.0     0.0      0.0  0.5003        3\n",
            "7               0.9553  0.5806   0.7223  0.7966      589\n",
            "8               0.9846  0.6598   0.7901   0.826       97\n",
            "9               0.7155  0.8469   0.7757   0.783       98\n",
            "10              0.9237  0.8984   0.9109  0.9141      256\n",
            "11              0.9698  0.4707   0.6338  0.7537      546\n",
            "12              0.9945  0.9982   0.9964  0.9965      548\n",
            "13              0.5905  0.6458   0.6169  0.6221       96\n",
            "14                 0.0     0.0      0.0  0.5008        7\n",
            "15              0.8276  0.5441   0.6565  0.7068      397\n",
            "16                 0.0     0.0      0.0  0.5002        2\n",
            "17               0.973  0.6667   0.7912  0.8219       54\n",
            "accuracy                          0.748                0\n",
            "macro avg       0.7127   0.637   0.6512   0.755     4321\n",
            "weighted avg    0.8656   0.748   0.7695     NaN     4321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}